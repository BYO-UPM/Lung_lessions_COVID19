{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773698f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:38:47.497345Z",
     "iopub.status.busy": "2022-10-27T06:38:47.496836Z",
     "iopub.status.idle": "2022-10-27T06:43:23.323472Z",
     "shell.execute_reply": "2022-10-27T06:43:23.321904Z"
    },
    "papermill": {
     "duration": 275.842667,
     "end_time": "2022-10-27T06:43:23.325974",
     "exception": false,
     "start_time": "2022-10-27T06:38:47.483307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmdetection'...\r\n",
      "remote: Enumerating objects: 24866, done.\u001b[K\r\n",
      "remote: Total 24866 (delta 0), reused 0 (delta 0), pack-reused 24866\u001b[K\r\n",
      "Receiving objects: 100% (24866/24866), 37.84 MiB | 22.39 MiB/s, done.\r\n",
      "Resolving deltas: 100% (17450/17450), done.\r\n",
      "/kaggle/working/mmdetection\n",
      "Obtaining file:///kaggle/working/mmdetection\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mmdet==2.25.1) (3.5.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmdet==2.25.1) (1.21.6)\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.5.tar.gz (24 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from mmdet==2.25.1) (1.16.0)\r\n",
      "Collecting terminaltables\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (1.4.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (3.0.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (0.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (2.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (21.3)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (4.33.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.25.1) (9.1.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.25.1) (4.1.1)\r\n",
      "Building wheels for collected packages: pycocotools\r\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.5-cp37-cp37m-linux_x86_64.whl size=373765 sha256=a9d8cdc9028fd77ae72c6abba1ce47147e092aba13bd8b0c68248e144971ecdf\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/c4/f0/7128093a134f590e4383fd60cb484960878721d98b9a515317\r\n",
      "Successfully built pycocotools\r\n",
      "Installing collected packages: terminaltables, pycocotools, mmdet\r\n",
      "  Running setup.py develop for mmdet\r\n",
      "Successfully installed mmdet-2.25.1 pycocotools-2.0.5 terminaltables-3.1.10\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m/kaggle/working\n",
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 10481, done.\u001b[K\r\n",
      "remote: Total 10481 (delta 0), reused 0 (delta 0), pack-reused 10481\u001b[K\r\n",
      "Receiving objects: 100% (10481/10481), 12.28 MiB | 17.39 MiB/s, done.\r\n",
      "Resolving deltas: 100% (7054/7054), done.\r\n",
      "/kaggle/working/yolov5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "/kaggle/working\n",
      "/kaggle/working/mmdetection\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -qq ensemble-boxes\n",
    "\n",
    "# Install mmcv\n",
    "!pip install -qq mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
    "\n",
    "    \n",
    "# Install mmdetection\n",
    "!git clone https://github.com/alvaromoure/mmdetection.git\n",
    "%cd mmdetection\n",
    "!pip install -e .\n",
    "\n",
    "\n",
    "# Install YoloV5\n",
    "%cd /kaggle/working\n",
    "!git clone https://github.com/alvaromoure/yolov5.git\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install dependencies\n",
    "%cd /kaggle/working\n",
    "%cd mmdetection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca7bc4",
   "metadata": {
    "papermill": {
     "duration": 0.014932,
     "end_time": "2022-10-27T06:43:23.357743",
     "exception": false,
     "start_time": "2022-10-27T06:43:23.342811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240b199b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:23.390223Z",
     "iopub.status.busy": "2022-10-27T06:43:23.389298Z",
     "iopub.status.idle": "2022-10-27T06:43:23.409190Z",
     "shell.execute_reply": "2022-10-27T06:43:23.408312Z"
    },
    "papermill": {
     "duration": 0.038361,
     "end_time": "2022-10-27T06:43:23.411103",
     "exception": false,
     "start_time": "2022-10-27T06:43:23.372742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bbox(row):\n",
    "    bboxes = []\n",
    "    bbox = []\n",
    "    for i, l in enumerate(row.label.split(' ')):\n",
    "        if (i % 6 == 0) | (i % 6 == 1):\n",
    "            continue\n",
    "        bbox.append(float(l))\n",
    "        if i % 6 == 5:\n",
    "            bboxes.append(bbox)\n",
    "            bbox = []  \n",
    "            \n",
    "    return bboxes\n",
    "\n",
    "# Scale the bounding boxes according to the size of the resized image. \n",
    "def scale_bbox(row, bboxes):\n",
    "    # Get scaling factor\n",
    "    scale_x = IMG_SIZE/row.dim1\n",
    "    scale_y = IMG_SIZE/row.dim0\n",
    "    \n",
    "    scaled_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x = int(np.round(bbox[0]*scale_x, 4))\n",
    "        y = int(np.round(bbox[1]*scale_y, 4))\n",
    "        x1 = int(np.round(bbox[2]*(scale_x), 4))\n",
    "        y1= int(np.round(bbox[3]*scale_y, 4))\n",
    "\n",
    "        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n",
    "        \n",
    "    return scaled_bboxes\n",
    "\n",
    "# Convert the bounding boxes in YOLO format.\n",
    "def get_yolo_format_bbox(img_w, img_h, bboxes):\n",
    "    yolo_boxes = []\n",
    "    for bbox in bboxes:\n",
    "        w = bbox[2] - bbox[0] # xmax - xmin\n",
    "        h = bbox[3] - bbox[1] # ymax - ymin\n",
    "        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n",
    "        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n",
    "        \n",
    "        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n",
    "    \n",
    "    return yolo_boxes\n",
    "\n",
    "def yolo_to_coco_bbox(img_size,bbox):\n",
    "    w = bbox[2]*img_size\n",
    "    h = bbox[3]*img_size\n",
    "    x1 = bbox[0]*img_size - w/2\n",
    "    y1 = bbox[1]*img_size - h/2\n",
    "    return [x1,y1,w,h]\n",
    "\n",
    "def get_bboxes_from_result(result,img_size):\n",
    "    boxes_list = []\n",
    "    for array in tqdm(result,total=len(result)):\n",
    "        for ann in array[0].tolist():\n",
    "            x1,y1,x2,y2 = [float(coord) for coord in ann[:4]]            \n",
    "            boxes_list.append([x1/img_size, y1/img_size, x2/img_size , y2/img_size])\n",
    "    return boxes_list\n",
    "        \n",
    "def get_scores_from_result(result):\n",
    "    scores_list = []\n",
    "    for array in tqdm(result,total=len(result)):\n",
    "        for ann in array[0].tolist():\n",
    "            score = float(ann[4])\n",
    "            scores_list.append(score)\n",
    "    return scores_list\n",
    "\n",
    "\n",
    "def normalize_bbox(bbox, w, h):\n",
    "    x1, y1, x2, y2 = [float(num) for num in bbox]\n",
    "    return [x1/w, y1/h, x2/w, y2/h]\n",
    "\n",
    "def resize_bbox(bbox, w, h):\n",
    "    x1, y1, x2, y2 = [float(num) for num in bbox]\n",
    "    return [x1*w, y1*h, x2*w, y2*h]\n",
    "\n",
    "def results_to_json(results):\n",
    "    out_results_list = []\n",
    "    for img_id,res_array in tqdm(enumerate(results)):\n",
    "        for ann in res_array[0]:\n",
    "            coords = ann[:4].tolist()\n",
    "            ann_dict = dict(\n",
    "                image_id = int(img_id),\n",
    "                bbox = [ coords[0], coords[1], coords[2]-coords[0] , coords[3]-coords[1] ],\n",
    "                score= float(ann[4]),\n",
    "                category_id = 0\n",
    "            )\n",
    "            out_results_list.append(ann_dict)\n",
    "    return out_results_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198e2d5",
   "metadata": {
    "papermill": {
     "duration": 0.014844,
     "end_time": "2022-10-27T06:43:23.440882",
     "exception": false,
     "start_time": "2022-10-27T06:43:23.426038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98e28df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:23.473055Z",
     "iopub.status.busy": "2022-10-27T06:43:23.471669Z",
     "iopub.status.idle": "2022-10-27T06:43:30.173359Z",
     "shell.execute_reply": "2022-10-27T06:43:30.172114Z"
    },
    "papermill": {
     "duration": 6.720092,
     "end_time": "2022-10-27T06:43:30.176018",
     "exception": false,
     "start_time": "2022-10-27T06:43:23.455926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch,torchvision\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from mmcv import Config\n",
    "\n",
    "import mmdet\n",
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "\n",
    "from ensemble_boxes import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pycocotools import cocoeval\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "def boom():\n",
    "    beep = np.sin(2*np.pi*400*np.arange(10000*3)/10000)\n",
    "    return ipd.Audio(beep, rate=10000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13abf9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:30.223480Z",
     "iopub.status.busy": "2022-10-27T06:43:30.222248Z",
     "iopub.status.idle": "2022-10-27T06:43:30.237743Z",
     "shell.execute_reply": "2022-10-27T06:43:30.232439Z"
    },
    "papermill": {
     "duration": 0.041204,
     "end_time": "2022-10-27T06:43:30.240227",
     "exception": false,
     "start_time": "2022-10-27T06:43:30.199023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_random_seed(seed, deterministic=False)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b1d2f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:30.290075Z",
     "iopub.status.busy": "2022-10-27T06:43:30.289573Z",
     "iopub.status.idle": "2022-10-27T06:43:31.904209Z",
     "shell.execute_reply": "2022-10-27T06:43:31.903005Z"
    },
    "papermill": {
     "duration": 1.641619,
     "end_time": "2022-10-27T06:43:31.906477",
     "exception": false,
     "start_time": "2022-10-27T06:43:30.264858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api = user_secrets.get_secret(\"wandb-key\") \n",
    "wandb.login(key=wandb_api,relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef13e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:31.940801Z",
     "iopub.status.busy": "2022-10-27T06:43:31.939994Z",
     "iopub.status.idle": "2022-10-27T06:43:31.944998Z",
     "shell.execute_reply": "2022-10-27T06:43:31.944089Z"
    },
    "papermill": {
     "duration": 0.024082,
     "end_time": "2022-10-27T06:43:31.947179",
     "exception": false,
     "start_time": "2022-10-27T06:43:31.923097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Final-Covid19-Detection'\n",
    "NOTEBOOK_NAME = 'TFM - Inference Firefox'\n",
    "EXP_NAME = 'Inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3361a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:31.980578Z",
     "iopub.status.busy": "2022-10-27T06:43:31.980203Z",
     "iopub.status.idle": "2022-10-27T06:43:34.843545Z",
     "shell.execute_reply": "2022-10-27T06:43:34.842594Z"
    },
    "papermill": {
     "duration": 2.882549,
     "end_time": "2022-10-27T06:43:34.845758",
     "exception": false,
     "start_time": "2022-10-27T06:43:31.963209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malvaromoureupm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/mmdetection/wandb/run-20221027_064332-29xqh48m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/29xqh48m\" target=\"_blank\">Inference_27/10_08:43</a></strong> to <a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytz\n",
    "timezone = pytz.timezone('Europe/Madrid')\n",
    "now = datetime.now(timezone)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m_%H:%M\")\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME,\n",
    "                 name=f'{EXP_NAME}_{dt_string}',\n",
    "                job_type='inference',\n",
    "                notes=f'Notebook: {NOTEBOOK_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4b39b",
   "metadata": {
    "papermill": {
     "duration": 0.015641,
     "end_time": "2022-10-27T06:43:34.877665",
     "exception": false,
     "start_time": "2022-10-27T06:43:34.862024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Geting Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a171ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:34.921205Z",
     "iopub.status.busy": "2022-10-27T06:43:34.920491Z",
     "iopub.status.idle": "2022-10-27T06:43:36.450177Z",
     "shell.execute_reply": "2022-10-27T06:43:36.449183Z"
    },
    "papermill": {
     "duration": 1.556319,
     "end_time": "2022-10-27T06:43:36.452832",
     "exception": false,
     "start_time": "2022-10-27T06:43:34.896513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_ann_file_0 = '/kaggle/working/coco_val_512x512_fold_0.json'\n",
    "val_ann_file_1 = '/kaggle/working/coco_val_512x512_fold_1.json'\n",
    "val_ann_file_2 = '/kaggle/working/coco_val_512x512_fold_2.json'\n",
    "val_ann_file_3 = '/kaggle/working/coco_val_512x512_fold_3.json'\n",
    "val_ann_file_4 = '/kaggle/working/coco_val_512x512_fold_4.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a6b0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:36.486106Z",
     "iopub.status.busy": "2022-10-27T06:43:36.485816Z",
     "iopub.status.idle": "2022-10-27T06:43:36.493597Z",
     "shell.execute_reply": "2022-10-27T06:43:36.492628Z"
    },
    "papermill": {
     "duration": 0.026631,
     "end_time": "2022-10-27T06:43:36.495576",
     "exception": false,
     "start_time": "2022-10-27T06:43:36.468945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_wandb_models(run,model_name,model_list):\n",
    "    downloaded_models = []\n",
    "    os.makedirs('/kaggle/tmp/downloaded_models',exist_ok=True)\n",
    "    for i,model in enumerate(tqdm(model_list)):\n",
    "        os.makedirs(f'/kaggle/tmp/downloaded_models/{model_name}',exist_ok=True)\n",
    "        artifact = run.use_artifact(f'alvaromoureupm/Final-Covid19-Detection/{model}')\n",
    "        download_dir = artifact.download()\n",
    "        model_files = os.listdir(download_dir)\n",
    "        for file in model_files:\n",
    "            if (file.endswith('.pth') or file.endswith('.pt')):\n",
    "                file_name = f'fold_{i}_{file}'\n",
    "            else:\n",
    "                file_name = file\n",
    "            shutil.copyfile(os.path.join(download_dir,file),f'/kaggle/tmp/downloaded_models/{model_name}/{file_name}')\n",
    "            if (file.endswith('.pth') or file.endswith('.pt')):\n",
    "                downloaded_models.append(file_name)\n",
    "    return downloaded_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b293d5",
   "metadata": {
    "papermill": {
     "duration": 0.016061,
     "end_time": "2022-10-27T06:43:36.527277",
     "exception": false,
     "start_time": "2022-10-27T06:43:36.511216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MMDET Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873dc644",
   "metadata": {
    "papermill": {
     "duration": 0.020213,
     "end_time": "2022-10-27T06:43:36.568211",
     "exception": false,
     "start_time": "2022-10-27T06:43:36.547998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957ff3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:43:36.600684Z",
     "iopub.status.busy": "2022-10-27T06:43:36.600419Z",
     "iopub.status.idle": "2022-10-27T06:45:55.138960Z",
     "shell.execute_reply": "2022-10-27T06:45:55.137158Z"
    },
    "papermill": {
     "duration": 138.559354,
     "end_time": "2022-10-27T06:45:55.143091",
     "exception": false,
     "start_time": "2022-10-27T06:43:36.583737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact RetinaNet_Fold_0:latest, 718.49MB. 2 files... Done. 0:0:10.0\n",
      " 20%|██        | 1/5 [00:11<00:47, 11.78s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact RetinaNet_Fold_1:latest, 718.49MB. 2 files... Done. 0:0:10.8\n",
      " 40%|████      | 2/5 [00:25<00:37, 12.66s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact RetinaNet_Fold_2:latest, 718.49MB. 2 files... Done. 0:0:10.7\n",
      " 60%|██████    | 3/5 [00:38<00:25, 12.94s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact RetinaNet_Fold_3:latest, 718.49MB. 2 files... Done. 0:0:33.2\n",
      " 80%|████████  | 4/5 [01:18<00:23, 23.67s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact RetinaNet_Fold_4:latest, 718.49MB. 2 files... Done. 0:0:52.8\n",
      "100%|██████████| 5/5 [02:18<00:00, 27.70s/it]\n"
     ]
    }
   ],
   "source": [
    "downloaded_retinanet = download_wandb_models(run,'RetinaNet',['RetinaNet_Fold_0:latest',\n",
    "                                                              'RetinaNet_Fold_1:latest',\n",
    "                                                             'RetinaNet_Fold_2:latest',\n",
    "                                                             'RetinaNet_Fold_3:latest',\n",
    "                                                             'RetinaNet_Fold_4:latest'])\n",
    "\n",
    "retinanet_checkpoint_0 = f'/kaggle/tmp/downloaded_models/RetinaNet/{downloaded_retinanet[0]}'\n",
    "retinanet_checkpoint_1 = f'/kaggle/tmp/downloaded_models/RetinaNet/{downloaded_retinanet[1]}'\n",
    "retinanet_checkpoint_2 = f'/kaggle/tmp/downloaded_models/RetinaNet/{downloaded_retinanet[2]}'\n",
    "retinanet_checkpoint_3 = f'/kaggle/tmp/downloaded_models/RetinaNet/{downloaded_retinanet[3]}'\n",
    "retinanet_checkpoint_4 = f'/kaggle/tmp/downloaded_models/RetinaNet/{downloaded_retinanet[4]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045ac8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:45:55.259877Z",
     "iopub.status.busy": "2022-10-27T06:45:55.259354Z",
     "iopub.status.idle": "2022-10-27T06:46:13.392705Z",
     "shell.execute_reply": "2022-10-27T06:46:13.391707Z"
    },
    "papermill": {
     "duration": 18.197137,
     "end_time": "2022-10-27T06:46:13.395067",
     "exception": false,
     "start_time": "2022-10-27T06:45:55.197930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_config = '/kaggle/tmp/downloaded_models/RetinaNet/retinanet.py'\n",
    "\n",
    "retina_cfg_0 = Config.fromfile(common_config)\n",
    "retina_cfg_0.data.test = retina_cfg_0.data.val\n",
    "retina_cfg_0.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "retina_cfg_0.data.test.ann_file = val_ann_file_0\n",
    "retina_cfg_0_file = '/kaggle/tmp/downloaded_models/RetinaNet/retina_cfg_0.py'\n",
    "retina_cfg_0.dump(retina_cfg_0_file)\n",
    "\n",
    "retina_cfg_1 = Config.fromfile(common_config)\n",
    "retina_cfg_1.data.test = retina_cfg_1.data.val\n",
    "retina_cfg_1.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "retina_cfg_1.data.test.ann_file = val_ann_file_1\n",
    "retina_cfg_1_file = '/kaggle/tmp/downloaded_models/RetinaNet/retina_cfg_1.py'\n",
    "retina_cfg_1.dump(retina_cfg_1_file)\n",
    "\n",
    "retina_cfg_2 = Config.fromfile(common_config)\n",
    "retina_cfg_2.data.test = retina_cfg_2.data.val\n",
    "retina_cfg_2.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "retina_cfg_2.data.test.ann_file = val_ann_file_2\n",
    "retina_cfg_2_file = '/kaggle/tmp/downloaded_models/RetinaNet/retina_cfg_2.py'\n",
    "retina_cfg_2.dump(retina_cfg_2_file)\n",
    "\n",
    "retina_cfg_3 = Config.fromfile(common_config)\n",
    "retina_cfg_3.data.test = retina_cfg_3.data.val\n",
    "retina_cfg_3.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "retina_cfg_3.data.test.ann_file = val_ann_file_3\n",
    "retina_cfg_3_file = '/kaggle/tmp/downloaded_models/RetinaNet/retina_cfg_3.py'\n",
    "retina_cfg_3.dump(retina_cfg_3_file)\n",
    "\n",
    "retina_cfg_4 = Config.fromfile(common_config)\n",
    "retina_cfg_4.data.test = retina_cfg_4.data.val\n",
    "retina_cfg_4.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "retina_cfg_4.data.test.ann_file = val_ann_file_4\n",
    "retina_cfg_4_file = '/kaggle/tmp/downloaded_models/RetinaNet/retina_cfg_4.py'\n",
    "retina_cfg_4.dump(retina_cfg_4_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b04a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T18:19:18.903155Z",
     "iopub.status.busy": "2022-10-19T18:19:18.902813Z",
     "iopub.status.idle": "2022-10-19T18:19:54.095999Z",
     "shell.execute_reply": "2022-10-19T18:19:54.094869Z",
     "shell.execute_reply.started": "2022-10-19T18:19:18.903117Z"
    },
    "papermill": {
     "duration": 0.016557,
     "end_time": "2022-10-27T06:46:13.429016",
     "exception": false,
     "start_time": "2022-10-27T06:46:13.412459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "retinanet_0 = init_detector(retina_cfg_0_file,retinanet_checkpoint_0,device='cuda:0')\n",
    "retinanet_0.CLASSES = ('Covid_Opacity',)\n",
    "retinanet_1 = init_detector(retina_cfg_1_file,retinanet_checkpoint_1,device='cuda:0')\n",
    "retinanet_1.CLASSES = ('Covid_Opacity',)\n",
    "retinanet_2 = init_detector(retina_cfg_2_file,retinanet_checkpoint_2,device='cuda:0')\n",
    "retinanet_2.CLASSES = ('Covid_Opacity',)\n",
    "retinanet_3 = init_detector(retina_cfg_3_file,retinanet_checkpoint_3,device='cuda:0')\n",
    "retinanet_3.CLASSES = ('Covid_Opacity',)\n",
    "retinanet_4 = init_detector(retina_cfg_4_file,retinanet_checkpoint_4,device='cuda:0')\n",
    "retinanet_4.CLASSES = ('Covid_Opacity',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ae1f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T06:46:13.463637Z",
     "iopub.status.busy": "2022-10-27T06:46:13.463338Z",
     "iopub.status.idle": "2022-10-27T07:07:26.866989Z",
     "shell.execute_reply": "2022-10-27T07:07:26.865852Z"
    },
    "papermill": {
     "duration": 1273.424,
     "end_time": "2022-10-27T07:07:26.869565",
     "exception": false,
     "start_time": "2022-10-27T06:46:13.445565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/RetinaNet/fold_0_best_bbox_mAP_50_epoch_16.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 3.8 task/s, elapsed: 229s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/retinanet/inference_results_0.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.21s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=4.86s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=1.69s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.545\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.053\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.197\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.351\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.452\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.171), ('bbox_mAP_50', 0.545), ('bbox_mAP_75', 0.053), ('bbox_mAP_s', 0.001), ('bbox_mAP_m', 0.054), ('bbox_mAP_l', 0.197), ('bbox_mAP_copypaste', '0.171 0.545 0.053 0.001 0.054 0.197')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/RetinaNet/fold_1_best_bbox_mAP_50_epoch_10.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 3.7 task/s, elapsed: 229s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/retinanet/inference_results_1.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.22s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=4.91s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=1.70s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.490\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.182\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.344\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.453\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.158), ('bbox_mAP_50', 0.49), ('bbox_mAP_75', 0.044), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.048), ('bbox_mAP_l', 0.182), ('bbox_mAP_copypaste', '0.158 0.490 0.044 0.000 0.048 0.182')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/RetinaNet/fold_2_best_bbox_mAP_50_epoch_10.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 3.8 task/s, elapsed: 228s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/retinanet/inference_results_2.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.22s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=4.80s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=1.82s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.543\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.201\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.437\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.437\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.461\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.175), ('bbox_mAP_50', 0.543), ('bbox_mAP_75', 0.059), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.032), ('bbox_mAP_l', 0.201), ('bbox_mAP_copypaste', '0.175 0.543 0.059 0.000 0.032 0.201')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/RetinaNet/fold_3_best_bbox_mAP_50_epoch_11.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 3.8 task/s, elapsed: 228s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/retinanet/inference_results_3.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.23s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=4.90s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=1.81s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.521\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.042\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.207\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.438\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.438\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.344\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.465\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.173), ('bbox_mAP_50', 0.521), ('bbox_mAP_75', 0.054), ('bbox_mAP_s', 0.015), ('bbox_mAP_m', 0.042), ('bbox_mAP_l', 0.207), ('bbox_mAP_copypaste', '0.173 0.521 0.054 0.015 0.042 0.207')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/RetinaNet/fold_4_best_bbox_mAP_50_epoch_7.pth\r\n",
      "[                                                  ] 0/858, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 858/858, 3.8 task/s, elapsed: 227s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/retinanet/inference_results_4.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.22s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=5.25s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=2.11s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.528\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.040\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.197\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.427\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.427\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.343\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.450\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.167), ('bbox_mAP_50', 0.528), ('bbox_mAP_75', 0.04), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.051), ('bbox_mAP_l', 0.197), ('bbox_mAP_copypaste', '0.167 0.528 0.040 0.000 0.051 0.197')])\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {retina_cfg_0_file} {retinanet_checkpoint_0}\\\n",
    "--out /kaggle/working/results/retinanet/inference_results_0.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/retinanet/result_images_0\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/retinanet/retinanet_0\"\n",
    "\n",
    "!python tools/test.py {retina_cfg_1_file} {retinanet_checkpoint_1}\\\n",
    "--out /kaggle/working/results/retinanet/inference_results_1.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/retinanet/result_images_1\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/retinanet/retinanet_1\"\n",
    "\n",
    "!python tools/test.py {retina_cfg_2_file} {retinanet_checkpoint_2}\\\n",
    "--out /kaggle/working/results/retinanet/inference_results_2.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/retinanet/result_images_2\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/retinanet/retinanet_2\"\n",
    "\n",
    "!python tools/test.py {retina_cfg_3_file} {retinanet_checkpoint_3}\\\n",
    "--out /kaggle/working/results/retinanet/inference_results_3.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/retinanet/result_images_3\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/retinanet/retinanet_3\"\n",
    "\n",
    "!python tools/test.py {retina_cfg_4_file} {retinanet_checkpoint_4}\\\n",
    "--out /kaggle/working/results/retinanet/inference_results_4.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/retinanet/result_images_4\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/retinanet/retinanet_4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76578ab",
   "metadata": {
    "papermill": {
     "duration": 0.228615,
     "end_time": "2022-10-27T07:07:27.509082",
     "exception": false,
     "start_time": "2022-10-27T07:07:27.280467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5-fold mAP@50 computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea9d01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:07:28.011434Z",
     "iopub.status.busy": "2022-10-27T07:07:28.011008Z",
     "iopub.status.idle": "2022-10-27T07:07:28.995117Z",
     "shell.execute_reply": "2022-10-27T07:07:28.994064Z"
    },
    "papermill": {
     "duration": 1.216294,
     "end_time": "2022-10-27T07:07:28.997607",
     "exception": false,
     "start_time": "2022-10-27T07:07:27.781313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_results_0.pkl  result_images_0  retinanet_0.bbox.json\r\n",
      "inference_results_1.pkl  result_images_1  retinanet_1.bbox.json\r\n",
      "inference_results_2.pkl  result_images_2  retinanet_2.bbox.json\r\n",
      "inference_results_3.pkl  result_images_3  retinanet_3.bbox.json\r\n",
      "inference_results_4.pkl  result_images_4  retinanet_4.bbox.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/results/retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afb4ef9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:07:29.463301Z",
     "iopub.status.busy": "2022-10-27T07:07:29.462159Z",
     "iopub.status.idle": "2022-10-27T07:08:01.967511Z",
     "shell.execute_reply": "2022-10-27T07:08:01.966267Z"
    },
    "papermill": {
     "duration": 32.737226,
     "end_time": "2022-10-27T07:08:01.969742",
     "exception": false,
     "start_time": "2022-10-27T07:07:29.232516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.88s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.68s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.490\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.58s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.67s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.543\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.61s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.69s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.521\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.465\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.61s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.83s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n"
     ]
    }
   ],
   "source": [
    "retina_mAP50_list = []\n",
    "for fold in range(5):\n",
    "    cocoGt = COCO(f'/kaggle/working/coco_val_512x512_fold_{fold}.json')\n",
    "    cocoDt = cocoGt.loadRes(f'/kaggle/working/results/retinanet/retinanet_{fold}.bbox.json')\n",
    "    imgIds=sorted(cocoGt.getImgIds())\n",
    "    cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "\n",
    "    cocoEval.params.catIds = [0] \n",
    "    cocoEval.evaluate()  \n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    mAP50 = cocoEval.stats[1]\n",
    "    retina_mAP50_list.append(mAP50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01615f",
   "metadata": {
    "papermill": {
     "duration": 0.22926,
     "end_time": "2022-10-27T07:08:02.475658",
     "exception": false,
     "start_time": "2022-10-27T07:08:02.246398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RetinaNet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d4067e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:08:02.937732Z",
     "iopub.status.busy": "2022-10-27T07:08:02.937030Z",
     "iopub.status.idle": "2022-10-27T07:08:02.947513Z",
     "shell.execute_reply": "2022-10-27T07:08:02.944846Z"
    },
    "papermill": {
     "duration": 0.244858,
     "end_time": "2022-10-27T07:08:02.950535",
     "exception": false,
     "start_time": "2022-10-27T07:08:02.705677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5254761053377951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(retina_mAP50_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a63ff",
   "metadata": {
    "papermill": {
     "duration": 0.226668,
     "end_time": "2022-10-27T07:08:03.405933",
     "exception": false,
     "start_time": "2022-10-27T07:08:03.179265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72ba852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:08:03.905329Z",
     "iopub.status.busy": "2022-10-27T07:08:03.904946Z",
     "iopub.status.idle": "2022-10-27T07:10:33.931251Z",
     "shell.execute_reply": "2022-10-27T07:10:33.930089Z"
    },
    "papermill": {
     "duration": 150.301638,
     "end_time": "2022-10-27T07:10:33.933751",
     "exception": false,
     "start_time": "2022-10-27T07:08:03.632113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact faster_rcnn_Fold0:v1, 457.55MB. 2 files... Done. 0:0:7.0\n",
      " 20%|██        | 1/5 [00:08<00:33,  8.41s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact faster_rcnn_Fold1:v0, 457.55MB. 2 files... Done. 0:0:7.7\n",
      " 40%|████      | 2/5 [00:17<00:27,  9.02s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact faster_rcnn_Fold2:v0, 457.55MB. 2 files... Done. 0:0:28.1\n",
      " 60%|██████    | 3/5 [00:47<00:36, 18.48s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact faster_rcnn_Fold3:v0, 457.55MB. 2 files... Done. 0:0:30.5\n",
      " 80%|████████  | 4/5 [01:24<00:25, 25.91s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact faster_rcnn_Fold4:v0, 457.55MB. 2 files... Done. 0:1:3.6\n",
      "100%|██████████| 5/5 [02:30<00:00, 30.00s/it]\n"
     ]
    }
   ],
   "source": [
    "downloaded_faster_rcnn = download_wandb_models(run,'Faster_RCNN',['faster_rcnn_Fold0:v1','faster_rcnn_Fold1:v0',\n",
    "                                                                    'faster_rcnn_Fold2:v0','faster_rcnn_Fold3:v0',\n",
    "                                                                   'faster_rcnn_Fold4:v0'])\n",
    "\n",
    "faster_checkpoint_0 = f'/kaggle/tmp/downloaded_models/Faster_RCNN/{downloaded_faster_rcnn[0]}'\n",
    "faster_checkpoint_1 = f'/kaggle/tmp/downloaded_models/Faster_RCNN/{downloaded_faster_rcnn[1]}'\n",
    "faster_checkpoint_2 = f'/kaggle/tmp/downloaded_models/Faster_RCNN/{downloaded_faster_rcnn[2]}'\n",
    "faster_checkpoint_3 = f'/kaggle/tmp/downloaded_models/Faster_RCNN/{downloaded_faster_rcnn[3]}'\n",
    "faster_checkpoint_4 = f'/kaggle/tmp/downloaded_models/Faster_RCNN/{downloaded_faster_rcnn[4]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bcbb128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:10:34.407912Z",
     "iopub.status.busy": "2022-10-27T07:10:34.407527Z",
     "iopub.status.idle": "2022-10-27T07:10:35.400740Z",
     "shell.execute_reply": "2022-10-27T07:10:35.399507Z"
    },
    "papermill": {
     "duration": 1.230676,
     "end_time": "2022-10-27T07:10:35.402877",
     "exception": false,
     "start_time": "2022-10-27T07:10:34.172201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/kaggle/working/downloaded_models/Faster_RCNN': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/downloaded_models/Faster_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f41b378e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:10:35.991714Z",
     "iopub.status.busy": "2022-10-27T07:10:35.991045Z",
     "iopub.status.idle": "2022-10-27T07:10:50.684377Z",
     "shell.execute_reply": "2022-10-27T07:10:50.682197Z"
    },
    "papermill": {
     "duration": 15.04296,
     "end_time": "2022-10-27T07:10:50.688155",
     "exception": false,
     "start_time": "2022-10-27T07:10:35.645195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_config = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_rcnn_x101_32x4d_fpn_1x_coco_faster_rcnn_Fold0.py'\n",
    "\n",
    "faster_cfg_0 = Config.fromfile(common_config)\n",
    "faster_cfg_0.data.test = faster_cfg_0.data.val\n",
    "faster_cfg_0.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "faster_cfg_0.data.test.ann_file = val_ann_file_0\n",
    "faster_cfg_0_file = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_cfg_0.py'\n",
    "faster_cfg_0.dump(faster_cfg_0_file)\n",
    "\n",
    "faster_cfg_1 = Config.fromfile(common_config)\n",
    "faster_cfg_1.data.test = faster_cfg_1.data.val\n",
    "faster_cfg_1.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "faster_cfg_1.data.test.ann_file = val_ann_file_1\n",
    "faster_cfg_1_file = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_cfg_1.py'\n",
    "faster_cfg_1.dump(faster_cfg_1_file)\n",
    "\n",
    "faster_cfg_2 = Config.fromfile(common_config)\n",
    "faster_cfg_2.data.test = faster_cfg_2.data.val\n",
    "faster_cfg_2.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "faster_cfg_2.data.test.ann_file = val_ann_file_2\n",
    "faster_cfg_2_file = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_cfg_2.py'\n",
    "faster_cfg_2.dump(faster_cfg_2_file)\n",
    "\n",
    "faster_cfg_3 = Config.fromfile(common_config)\n",
    "faster_cfg_3.data.test = faster_cfg_3.data.val\n",
    "faster_cfg_3.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "faster_cfg_3.data.test.ann_file = val_ann_file_3\n",
    "faster_cfg_3_file = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_cfg_3.py'\n",
    "faster_cfg_3.dump(faster_cfg_3_file)\n",
    "\n",
    "faster_cfg_4 = Config.fromfile(common_config)\n",
    "faster_cfg_4.data.test = faster_cfg_4.data.val\n",
    "faster_cfg_4.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "faster_cfg_4.data.test.ann_file = val_ann_file_4\n",
    "faster_cfg_4_file = '/kaggle/tmp/downloaded_models/Faster_RCNN/faster_cfg_4.py'\n",
    "faster_cfg_4.dump(faster_cfg_4_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e1f288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:10:51.149874Z",
     "iopub.status.busy": "2022-10-27T07:10:51.149508Z",
     "iopub.status.idle": "2022-10-27T07:27:53.444939Z",
     "shell.execute_reply": "2022-10-27T07:27:53.443812Z"
    },
    "papermill": {
     "duration": 1022.527715,
     "end_time": "2022-10-27T07:27:53.447676",
     "exception": false,
     "start_time": "2022-10-27T07:10:50.919961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Faster_RCNN/fold_0_epoch_10.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.5 task/s, elapsed: 190s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/faster_rcnn/inference_results_0.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.83s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.23s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.572\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.064\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.211\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.352\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.352\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.197\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.389\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.183), ('bbox_mAP_50', 0.572), ('bbox_mAP_75', 0.064), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.054), ('bbox_mAP_l', 0.211), ('bbox_mAP_copypaste', '0.183 0.572 0.064 0.000 0.054 0.211')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Faster_RCNN/fold_1_epoch_11.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.5 task/s, elapsed: 190s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/faster_rcnn/inference_results_1.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.90s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.25s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.519\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.191\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.386\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.165), ('bbox_mAP_50', 0.519), ('bbox_mAP_75', 0.05), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.052), ('bbox_mAP_l', 0.191), ('bbox_mAP_copypaste', '0.165 0.519 0.050 0.000 0.052 0.191')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.02s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Faster_RCNN/fold_2_epoch_12.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.5 task/s, elapsed: 190s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/faster_rcnn/inference_results_2.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.71s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.22s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.558\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.063\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.215\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.141\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.387\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.186), ('bbox_mAP_50', 0.558), ('bbox_mAP_75', 0.063), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.023), ('bbox_mAP_l', 0.215), ('bbox_mAP_copypaste', '0.186 0.558 0.063 0.000 0.023 0.215')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.02s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Faster_RCNN/fold_3_epoch_10.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.5 task/s, elapsed: 191s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/faster_rcnn/inference_results_3.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.77s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.26s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.533\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.056\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.204\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.100\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.175\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.386\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.17), ('bbox_mAP_50', 0.533), ('bbox_mAP_75', 0.056), ('bbox_mAP_s', 0.002), ('bbox_mAP_m', 0.041), ('bbox_mAP_l', 0.204), ('bbox_mAP_copypaste', '0.170 0.533 0.056 0.002 0.041 0.204')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Faster_RCNN/fold_4_epoch_10.pth\r\n",
      "[                                                  ] 0/858, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 858/858, 4.5 task/s, elapsed: 191s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/faster_rcnn/inference_results_4.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.89s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.24s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.577\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.063\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.040\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.221\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.162\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.398\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.187), ('bbox_mAP_50', 0.577), ('bbox_mAP_75', 0.063), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.04), ('bbox_mAP_l', 0.221), ('bbox_mAP_copypaste', '0.187 0.577 0.063 0.000 0.040 0.221')])\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {faster_cfg_0_file} {faster_checkpoint_0}\\\n",
    "--out /kaggle/working/results/faster_rcnn/inference_results_0.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/faster_rcnn/result_images_0\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/faster_rcnn/faster_0\"\n",
    "\n",
    "!python tools/test.py {faster_cfg_1_file} {faster_checkpoint_1}\\\n",
    "--out /kaggle/working/results/faster_rcnn/inference_results_1.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/faster_rcnn/result_images_1\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/faster_rcnn/faster_1\"\n",
    "\n",
    "!python tools/test.py {faster_cfg_2_file} {faster_checkpoint_2}\\\n",
    "--out /kaggle/working/results/faster_rcnn/inference_results_2.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/faster_rcnn/result_images_2\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/faster_rcnn/faster_2\"\n",
    "\n",
    "!python tools/test.py {faster_cfg_3_file} {faster_checkpoint_3}\\\n",
    "--out /kaggle/working/results/faster_rcnn/inference_results_3.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/faster_rcnn/result_images_3\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/faster_rcnn/faster_3\"\n",
    "\n",
    "!python tools/test.py {faster_cfg_4_file} {faster_checkpoint_4}\\\n",
    "--out /kaggle/working/results/faster_rcnn/inference_results_4.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/faster_rcnn/result_images_4\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/faster_rcnn/faster_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a415c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:27:54.499707Z",
     "iopub.status.busy": "2022-10-27T07:27:54.499320Z",
     "iopub.status.idle": "2022-10-27T07:27:55.466627Z",
     "shell.execute_reply": "2022-10-27T07:27:55.465524Z"
    },
    "papermill": {
     "duration": 1.41638,
     "end_time": "2022-10-27T07:27:55.469096",
     "exception": false,
     "start_time": "2022-10-27T07:27:54.052716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_0.bbox.json  inference_results_0.pkl  result_images_0\r\n",
      "faster_1.bbox.json  inference_results_1.pkl  result_images_1\r\n",
      "faster_2.bbox.json  inference_results_2.pkl  result_images_2\r\n",
      "faster_3.bbox.json  inference_results_3.pkl  result_images_3\r\n",
      "faster_4.bbox.json  inference_results_4.pkl  result_images_4\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/results/faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eecfa56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:27:56.426416Z",
     "iopub.status.busy": "2022-10-27T07:27:56.426021Z",
     "iopub.status.idle": "2022-10-27T07:28:03.115543Z",
     "shell.execute_reply": "2022-10-27T07:28:03.114504Z"
    },
    "papermill": {
     "duration": 7.139492,
     "end_time": "2022-10-27T07:28:03.117766",
     "exception": false,
     "start_time": "2022-10-27T07:27:55.978274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.77s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.78s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.83s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.577\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n"
     ]
    }
   ],
   "source": [
    "mAP50_list = []\n",
    "for fold in range(5):\n",
    "    cocoGt = COCO(f'/kaggle/working/coco_val_512x512_fold_{fold}.json')\n",
    "    cocoDt = cocoGt.loadRes(f'/kaggle/working/results/faster_rcnn/faster_{fold}.bbox.json')\n",
    "    imgIds=sorted(cocoGt.getImgIds())\n",
    "    cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "\n",
    "    cocoEval.params.catIds = [0] \n",
    "    cocoEval.evaluate()  \n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    mAP50 = cocoEval.stats[1]\n",
    "    mAP50_list.append(mAP50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a3f2526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:28:04.041398Z",
     "iopub.status.busy": "2022-10-27T07:28:04.041014Z",
     "iopub.status.idle": "2022-10-27T07:28:04.052109Z",
     "shell.execute_reply": "2022-10-27T07:28:04.051078Z"
    },
    "papermill": {
     "duration": 0.465941,
     "end_time": "2022-10-27T07:28:04.055050",
     "exception": false,
     "start_time": "2022-10-27T07:28:03.589109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5517452074712978"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mAP50_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b3721",
   "metadata": {
    "papermill": {
     "duration": 0.441809,
     "end_time": "2022-10-27T07:28:04.987281",
     "exception": false,
     "start_time": "2022-10-27T07:28:04.545472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cascade R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69bdb121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:28:05.925173Z",
     "iopub.status.busy": "2022-10-27T07:28:05.924790Z",
     "iopub.status.idle": "2022-10-27T07:34:58.241707Z",
     "shell.execute_reply": "2022-10-27T07:34:58.240462Z"
    },
    "papermill": {
     "duration": 412.825259,
     "end_time": "2022-10-27T07:34:58.253618",
     "exception": false,
     "start_time": "2022-10-27T07:28:05.428359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact cascade_rcnn_x101_Fold0:v0, 669.69MB. 2 files... Done. 0:0:9.3\n",
      " 20%|██        | 1/5 [00:11<00:44, 11.04s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact cascade_rcnn_x101_Fold1:v0, 669.69MB. 2 files... Done. 0:1:49.7\n",
      " 40%|████      | 2/5 [02:02<03:30, 70.31s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact cascade_rcnn_x101_Fold2:v0, 669.69MB. 2 files... Done. 0:1:10.2\n",
      " 60%|██████    | 3/5 [03:15<02:22, 71.23s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact cascade_rcnn_x101_Fold3:v0, 669.69MB. 2 files... Done. 0:1:29.8\n",
      " 80%|████████  | 4/5 [04:47<01:19, 79.42s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact cascade_rcnn_x101_Fold4:v0, 669.69MB. 2 files... Done. 0:1:58.1\n",
      "100%|██████████| 5/5 [06:52<00:00, 82.46s/it]\n"
     ]
    }
   ],
   "source": [
    "downloaded_cascade_rcnn = download_wandb_models(run,'Cascade_RCNN',['cascade_rcnn_x101_Fold0:v0','cascade_rcnn_x101_Fold1:v0',\n",
    "                                                                    'cascade_rcnn_x101_Fold2:v0','cascade_rcnn_x101_Fold3:v0',\n",
    "                                                                   'cascade_rcnn_x101_Fold4:v0'])\n",
    "\n",
    "cascade_checkpoint_0 = f'/kaggle/tmp/downloaded_models/Cascade_RCNN/{downloaded_cascade_rcnn[0]}'\n",
    "cascade_checkpoint_1 = f'/kaggle/tmp/downloaded_models/Cascade_RCNN/{downloaded_cascade_rcnn[1]}'\n",
    "cascade_checkpoint_2 = f'/kaggle/tmp/downloaded_models/Cascade_RCNN/{downloaded_cascade_rcnn[2]}'\n",
    "cascade_checkpoint_3 = f'/kaggle/tmp/downloaded_models/Cascade_RCNN/{downloaded_cascade_rcnn[3]}'\n",
    "cascade_checkpoint_4 = f'/kaggle/tmp/downloaded_models/Cascade_RCNN/{downloaded_cascade_rcnn[4]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ebbb17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:35:00.595472Z",
     "iopub.status.busy": "2022-10-27T07:35:00.594947Z",
     "iopub.status.idle": "2022-10-27T07:35:01.700817Z",
     "shell.execute_reply": "2022-10-27T07:35:01.699505Z"
    },
    "papermill": {
     "duration": 2.671686,
     "end_time": "2022-10-27T07:35:01.703804",
     "exception": false,
     "start_time": "2022-10-27T07:34:59.032118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/kaggle/working/downloaded_models/Cascade_RCNN': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/downloaded_models/Cascade_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4dac6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:35:02.731043Z",
     "iopub.status.busy": "2022-10-27T07:35:02.730656Z",
     "iopub.status.idle": "2022-10-27T07:35:19.669258Z",
     "shell.execute_reply": "2022-10-27T07:35:19.668257Z"
    },
    "papermill": {
     "duration": 17.488754,
     "end_time": "2022-10-27T07:35:19.671976",
     "exception": false,
     "start_time": "2022-10-27T07:35:02.183222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_config = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_rcnn_x101_32x4d_fpn_1x_coco_cascade_rcnn_x101_Fold0.py'\n",
    "\n",
    "cascade_cfg_0 = Config.fromfile(common_config)\n",
    "cascade_cfg_0.data.test = cascade_cfg_0.data.val\n",
    "cascade_cfg_0.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "cascade_cfg_0.data.test.ann_file = val_ann_file_0\n",
    "cascade_cfg_0_file = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_cfg_0.py'\n",
    "cascade_cfg_0.dump(cascade_cfg_0_file)\n",
    "\n",
    "cascade_cfg_1 = Config.fromfile(common_config)\n",
    "cascade_cfg_1.data.test = cascade_cfg_1.data.val\n",
    "cascade_cfg_1.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "cascade_cfg_1.data.test.ann_file = val_ann_file_1\n",
    "cascade_cfg_1_file = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_cfg_1.py'\n",
    "cascade_cfg_1.dump(cascade_cfg_1_file)\n",
    "\n",
    "cascade_cfg_2 = Config.fromfile(common_config)\n",
    "cascade_cfg_2.data.test = cascade_cfg_2.data.val\n",
    "cascade_cfg_2.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "cascade_cfg_2.data.test.ann_file = val_ann_file_2\n",
    "cascade_cfg_2_file = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_cfg_2.py'\n",
    "cascade_cfg_2.dump(cascade_cfg_2_file)\n",
    "\n",
    "cascade_cfg_3 = Config.fromfile(common_config)\n",
    "cascade_cfg_3.data.test = cascade_cfg_3.data.val\n",
    "cascade_cfg_3.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "cascade_cfg_3.data.test.ann_file = val_ann_file_3\n",
    "cascade_cfg_3_file = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_cfg_3.py'\n",
    "cascade_cfg_3.dump(cascade_cfg_3_file)\n",
    "\n",
    "cascade_cfg_4 = Config.fromfile(common_config)\n",
    "cascade_cfg_4.data.test = cascade_cfg_4.data.val\n",
    "cascade_cfg_4.data.test.img_prefix = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "cascade_cfg_4.data.test.ann_file = val_ann_file_4\n",
    "cascade_cfg_4_file = '/kaggle/tmp/downloaded_models/Cascade_RCNN/cascade_cfg_4.py'\n",
    "cascade_cfg_4.dump(cascade_cfg_4_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd63a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T10:43:52.283898Z",
     "iopub.status.busy": "2022-10-22T10:43:52.283504Z",
     "iopub.status.idle": "2022-10-22T10:44:27.874734Z",
     "shell.execute_reply": "2022-10-22T10:44:27.873077Z",
     "shell.execute_reply.started": "2022-10-22T10:43:52.283868Z"
    },
    "papermill": {
     "duration": 0.43847,
     "end_time": "2022-10-27T07:35:20.562091",
     "exception": false,
     "start_time": "2022-10-27T07:35:20.123621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "cascade_0 = init_detector(cascade_cfg_0_file,cascade_checkpoint_0,device='cuda:0')\n",
    "cascade_0.CLASSES = ('Covid_Opacity',)\n",
    "\n",
    "cascade_1 = init_detector(cascade_cfg_1_file,cascade_checkpoint_1,device='cuda:0')\n",
    "cascade_1.CLASSES = ('Covid_Opacity',)\n",
    "\n",
    "cascade_2 = init_detector(cascade_cfg_2_file,cascade_checkpoint_2,device='cuda:0')\n",
    "cascade_2.CLASSES = ('Covid_Opacity',)\n",
    "\n",
    "cascade_3 = init_detector(cascade_cfg_3_file,cascade_checkpoint_3,device='cuda:0')\n",
    "cascade_3.CLASSES = ('Covid_Opacity',)\n",
    "\n",
    "cascade_4 = init_detector(cascade_cfg_4_file,cascade_checkpoint_4,device='cuda:0')\n",
    "cascade_4.CLASSES = ('Covid_Opacity',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e86eb49d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:35:21.503662Z",
     "iopub.status.busy": "2022-10-27T07:35:21.503309Z",
     "iopub.status.idle": "2022-10-27T07:53:55.473094Z",
     "shell.execute_reply": "2022-10-27T07:53:55.471949Z"
    },
    "papermill": {
     "duration": 1114.470273,
     "end_time": "2022-10-27T07:53:55.475503",
     "exception": false,
     "start_time": "2022-10-27T07:35:21.005230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Cascade_RCNN/fold_0_epoch_9.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.2 task/s, elapsed: 207s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/cascade_rcnn/inference_results_0.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.75s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.23s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.536\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.069\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.206\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.357\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.357\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.210\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.393\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.179), ('bbox_mAP_50', 0.536), ('bbox_mAP_75', 0.067), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.069), ('bbox_mAP_l', 0.206), ('bbox_mAP_copypaste', '0.179 0.536 0.067 0.000 0.069 0.206')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Cascade_RCNN/fold_1_epoch_9.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.2 task/s, elapsed: 206s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/cascade_rcnn/inference_results_1.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.79s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.22s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.508\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.049\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.183\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.328\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.328\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.100\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.177\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.364\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.158), ('bbox_mAP_50', 0.508), ('bbox_mAP_75', 0.049), ('bbox_mAP_s', 0.026), ('bbox_mAP_m', 0.044), ('bbox_mAP_l', 0.183), ('bbox_mAP_copypaste', '0.158 0.508 0.049 0.026 0.044 0.183')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Cascade_RCNN/fold_2_epoch_6.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.1 task/s, elapsed: 209s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/cascade_rcnn/inference_results_2.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.11s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.68s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.22s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.561\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.068\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.216\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.354\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.354\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.152\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.393\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.188), ('bbox_mAP_50', 0.561), ('bbox_mAP_75', 0.068), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.031), ('bbox_mAP_l', 0.216), ('bbox_mAP_copypaste', '0.188 0.561 0.068 0.000 0.031 0.216')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Cascade_RCNN/fold_3_epoch_9.pth\r\n",
      "[                                                  ] 0/859, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 859/859, 4.1 task/s, elapsed: 207s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/cascade_rcnn/inference_results_3.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.78s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.19s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.537\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.045\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.209\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.168\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.385\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.175), ('bbox_mAP_50', 0.537), ('bbox_mAP_75', 0.067), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.045), ('bbox_mAP_l', 0.209), ('bbox_mAP_copypaste', '0.175 0.537 0.067 0.000 0.045 0.209')])\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/kaggle/working/mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.02s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /kaggle/tmp/downloaded_models/Cascade_RCNN/fold_4_epoch_8.pth\r\n",
      "[                                                  ] 0/858, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 858/858, 4.1 task/s, elapsed: 207s, ETA:     0s\r\n",
      "writing results to /kaggle/working/results/cascade_rcnn/inference_results_4.pkl\r\n",
      "\r\n",
      "Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.77s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.20s).\r\n",
      "\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.551\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.082\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.228\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.180\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.390\r\n",
      "\r\n",
      "OrderedDict([('bbox_mAP', 0.192), ('bbox_mAP_50', 0.551), ('bbox_mAP_75', 0.082), ('bbox_mAP_s', 0.0), ('bbox_mAP_m', 0.036), ('bbox_mAP_l', 0.228), ('bbox_mAP_copypaste', '0.192 0.551 0.082 0.000 0.036 0.228')])\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {cascade_cfg_0_file} {cascade_checkpoint_0}\\\n",
    "--out /kaggle/working/results/cascade_rcnn/inference_results_0.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/cascade_rcnn/result_images_0\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/cascade_rcnn/cascade_0\"\n",
    "\n",
    "!python tools/test.py {cascade_cfg_1_file} {cascade_checkpoint_1}\\\n",
    "--out /kaggle/working/results/cascade_rcnn/inference_results_1.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/cascade_rcnn/result_images_1\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/cascade_rcnn/cascade_1\"\n",
    "\n",
    "!python tools/test.py {cascade_cfg_2_file} {cascade_checkpoint_2}\\\n",
    "--out /kaggle/working/results/cascade_rcnn/inference_results_2.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/cascade_rcnn/result_images_2\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/cascade_rcnn/cascade_2\"\n",
    "\n",
    "!python tools/test.py {cascade_cfg_3_file} {cascade_checkpoint_3}\\\n",
    "--out /kaggle/working/results/cascade_rcnn/inference_results_3.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/cascade_rcnn/result_images_3\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/cascade_rcnn/cascade_3\"\n",
    "\n",
    "!python tools/test.py {cascade_cfg_4_file} {cascade_checkpoint_4}\\\n",
    "--out /kaggle/working/results/cascade_rcnn/inference_results_4.pkl\\\n",
    "--eval bbox\\\n",
    "--show-dir /kaggle/working/results/cascade_rcnn/result_images_4\\\n",
    "--show-score-thr 0.3 \\\n",
    "--eval-options \"jsonfile_prefix=/kaggle/working/results/cascade_rcnn/cascade_4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6180a577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:53:56.889933Z",
     "iopub.status.busy": "2022-10-27T07:53:56.889537Z",
     "iopub.status.idle": "2022-10-27T07:53:57.887535Z",
     "shell.execute_reply": "2022-10-27T07:53:57.886440Z"
    },
    "papermill": {
     "duration": 1.675614,
     "end_time": "2022-10-27T07:53:57.889910",
     "exception": false,
     "start_time": "2022-10-27T07:53:56.214296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cascade_0.bbox.json  inference_results_0.pkl  result_images_0\r\n",
      "cascade_1.bbox.json  inference_results_1.pkl  result_images_1\r\n",
      "cascade_2.bbox.json  inference_results_2.pkl  result_images_2\r\n",
      "cascade_3.bbox.json  inference_results_3.pkl  result_images_3\r\n",
      "cascade_4.bbox.json  inference_results_4.pkl  result_images_4\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/results/cascade_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ee5eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:53:59.600773Z",
     "iopub.status.busy": "2022-10-27T07:53:59.599385Z",
     "iopub.status.idle": "2022-10-27T07:54:05.492096Z",
     "shell.execute_reply": "2022-10-27T07:54:05.490091Z"
    },
    "papermill": {
     "duration": 6.871461,
     "end_time": "2022-10-27T07:54:05.494848",
     "exception": false,
     "start_time": "2022-10-27T07:53:58.623387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.508\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.537\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.551\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n"
     ]
    }
   ],
   "source": [
    "mAP50_list = []\n",
    "for fold in range(5):\n",
    "    cocoGt = COCO(f'/kaggle/working/coco_val_512x512_fold_{fold}.json')\n",
    "    cocoDt = cocoGt.loadRes(f'/kaggle/working/results/cascade_rcnn/cascade_{fold}.bbox.json')\n",
    "    imgIds=sorted(cocoGt.getImgIds())\n",
    "    cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "\n",
    "    cocoEval.params.catIds = [0] \n",
    "    cocoEval.evaluate()  \n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    mAP50 = cocoEval.stats[1]\n",
    "    mAP50_list.append(mAP50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8321e5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:06.896533Z",
     "iopub.status.busy": "2022-10-27T07:54:06.896169Z",
     "iopub.status.idle": "2022-10-27T07:54:06.906393Z",
     "shell.execute_reply": "2022-10-27T07:54:06.905472Z"
    },
    "papermill": {
     "duration": 0.692551,
     "end_time": "2022-10-27T07:54:06.911995",
     "exception": false,
     "start_time": "2022-10-27T07:54:06.219444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.535649681927193,\n",
       " 0.5080350658687016,\n",
       " 0.5612143250249109,\n",
       " 0.5373451512693791,\n",
       " 0.5505163351805352]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP50_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1a4918a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:08.299622Z",
     "iopub.status.busy": "2022-10-27T07:54:08.299256Z",
     "iopub.status.idle": "2022-10-27T07:54:08.307547Z",
     "shell.execute_reply": "2022-10-27T07:54:08.306183Z"
    },
    "papermill": {
     "duration": 0.679183,
     "end_time": "2022-10-27T07:54:08.312090",
     "exception": false,
     "start_time": "2022-10-27T07:54:07.632907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.538552111854144"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mAP50_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdbd7d",
   "metadata": {
    "papermill": {
     "duration": 0.663409,
     "end_time": "2022-10-27T07:54:09.698636",
     "exception": false,
     "start_time": "2022-10-27T07:54:09.035227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e352ec92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:11.308302Z",
     "iopub.status.busy": "2022-10-27T07:54:11.307919Z",
     "iopub.status.idle": "2022-10-27T07:54:11.314353Z",
     "shell.execute_reply": "2022-10-27T07:54:11.313391Z"
    },
    "papermill": {
     "duration": 0.7322,
     "end_time": "2022-10-27T07:54:11.317034",
     "exception": false,
     "start_time": "2022-10-27T07:54:10.584834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIZE = 512\n",
    "IMG_SIZE = SIZE\n",
    "size = SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62ae91",
   "metadata": {
    "papermill": {
     "duration": 0.660196,
     "end_time": "2022-10-27T07:54:12.702891",
     "exception": false,
     "start_time": "2022-10-27T07:54:12.042695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f37f93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:14.098901Z",
     "iopub.status.busy": "2022-10-27T07:54:14.098538Z",
     "iopub.status.idle": "2022-10-27T07:54:14.108940Z",
     "shell.execute_reply": "2022-10-27T07:54:14.107987Z"
    },
    "papermill": {
     "duration": 0.685327,
     "end_time": "2022-10-27T07:54:14.112490",
     "exception": false,
     "start_time": "2022-10-27T07:54:13.427163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/images')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/images/train')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/images/val')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/labels')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/labels/train')\n",
    "    os.makedirs(f'/kaggle/tmp/dataset/{fold}/labels/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56e55f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:15.504936Z",
     "iopub.status.busy": "2022-10-27T07:54:15.504573Z",
     "iopub.status.idle": "2022-10-27T07:54:31.274869Z",
     "shell.execute_reply": "2022-10-27T07:54:31.273998Z"
    },
    "papermill": {
     "duration": 16.454752,
     "end_time": "2022-10-27T07:54:31.288515",
     "exception": false,
     "start_time": "2022-10-27T07:54:14.833763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 859/859 [00:00<00:00, 999142.30it/s]\n",
      "100%|██████████| 859/859 [00:06<00:00, 137.94it/s]\n",
      "100%|██████████| 859/859 [00:00<00:00, 952645.99it/s]\n",
      "100%|██████████| 859/859 [00:05<00:00, 162.42it/s]\n",
      "100%|██████████| 859/859 [00:00<00:00, 902531.85it/s]\n",
      "100%|██████████| 859/859 [00:01<00:00, 464.05it/s]\n",
      "100%|██████████| 859/859 [00:00<00:00, 876406.50it/s]\n",
      "100%|██████████| 859/859 [00:01<00:00, 727.17it/s]\n",
      "100%|██████████| 858/858 [00:00<00:00, 860113.01it/s]\n",
      "100%|██████████| 858/858 [00:01<00:00, 758.62it/s]\n"
     ]
    }
   ],
   "source": [
    "val_ann_file_list = [val_ann_file_0,val_ann_file_1,val_ann_file_2,val_ann_file_3,val_ann_file_4]\n",
    "val_image_paths_list = []\n",
    "\n",
    "for fold in range(5):\n",
    "    val_ann_file = val_ann_file_list[fold]\n",
    "    with open(val_ann_file,'rb') as file:\n",
    "        val_dict = json.load(file)\n",
    "    val_image_paths = []\n",
    "    for item in tqdm(val_dict['images']):\n",
    "        val_image_paths.append(item['file_name'])\n",
    "    val_image_paths_list.append(val_image_paths)\n",
    "    for image in tqdm(val_image_paths):\n",
    "        image_id = image.split('_')[0]\n",
    "        shutil.copyfile(os.path.join('/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512',\n",
    "                                 image),f'/kaggle/tmp/dataset/{fold}/images/val/{image_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8c38e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:54:33.390750Z",
     "iopub.status.busy": "2022-10-27T07:54:33.390391Z",
     "iopub.status.idle": "2022-10-27T07:55:18.989051Z",
     "shell.execute_reply": "2022-10-27T07:55:18.987978Z"
    },
    "papermill": {
     "duration": 46.458781,
     "end_time": "2022-10-27T07:55:18.990992",
     "exception": false,
     "start_time": "2022-10-27T07:54:32.532211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing images in folder: /kaggle/tmp/dataset/0/images/val/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 859/859 [00:08<00:00, 99.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing images in folder: /kaggle/tmp/dataset/1/images/val/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 859/859 [00:08<00:00, 97.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing images in folder: /kaggle/tmp/dataset/2/images/val/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 859/859 [00:08<00:00, 95.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing images in folder: /kaggle/tmp/dataset/3/images/val/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 859/859 [00:10<00:00, 84.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing images in folder: /kaggle/tmp/dataset/4/images/val/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 858/858 [00:08<00:00, 97.05it/s] \n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    base_val_path = f'/kaggle/tmp/dataset/{fold}/images/val/'\n",
    "    print(f'preprocessing images in folder: {base_val_path} ...')\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0)\n",
    "    for image in tqdm(os.listdir(base_val_path)):\n",
    "        full_image_path = os.path.join(base_val_path,image)\n",
    "        img = cv2.imread(full_image_path,cv2.IMREAD_UNCHANGED)\n",
    "        img_eq = cv2.equalizeHist(img)\n",
    "        img_clahe = clahe.apply(img_eq)\n",
    "        cv2.imwrite(full_image_path,img_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc7474d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:55:20.437474Z",
     "iopub.status.busy": "2022-10-27T07:55:20.437095Z",
     "iopub.status.idle": "2022-10-27T07:55:20.450155Z",
     "shell.execute_reply": "2022-10-27T07:55:20.449065Z"
    },
    "papermill": {
     "duration": 0.762445,
     "end_time": "2022-10-27T07:55:20.452988",
     "exception": false,
     "start_time": "2022-10-27T07:55:19.690543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "for fold in range(5):\n",
    "    data_yaml = dict(\n",
    "        path = f'/kaggle/tmp/dataset/{fold}',\n",
    "        train = 'images/train/',\n",
    "        val = 'images/val/',\n",
    "        nc=1,\n",
    "        names = ['Covid_Opacity',]\n",
    "    )\n",
    "\n",
    "    with open(f'/kaggle/working/yolov5/data/data_fold{fold}.yaml','w') as file:\n",
    "        yaml.dump(data_yaml,file,default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e047dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:55:21.901069Z",
     "iopub.status.busy": "2022-10-27T07:55:21.900703Z",
     "iopub.status.idle": "2022-10-27T07:55:22.281401Z",
     "shell.execute_reply": "2022-10-27T07:55:22.280450Z"
    },
    "papermill": {
     "duration": 1.076914,
     "end_time": "2022-10-27T07:55:22.283656",
     "exception": false,
     "start_time": "2022-10-27T07:55:21.206742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\n",
    "df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n",
    "df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n",
    "meta_df = pd.read_csv(f'/kaggle/input/siim-covid-19-256-512-768-1024-1280/train_meta_{size}x{size}.csv')\n",
    "meta_df['id'] = meta_df.apply(lambda row: row.id.split('_')[0], axis=1)\n",
    "meta_df.drop('folder_id',inplace=True,axis=1)\n",
    "meta_df.drop('study_id',inplace=True,axis=1)\n",
    "meta_df['dim0'] = meta_df['height']\n",
    "meta_df['dim1'] = meta_df['width']\n",
    "meta_df.drop('width',inplace=True,axis=1)\n",
    "meta_df.drop('height',inplace=True,axis=1)\n",
    "df = df.merge(meta_df, on='id',how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f5b9455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:55:23.753221Z",
     "iopub.status.busy": "2022-10-27T07:55:23.752710Z",
     "iopub.status.idle": "2022-10-27T07:55:29.094276Z",
     "shell.execute_reply": "2022-10-27T07:55:29.093195Z"
    },
    "papermill": {
     "duration": 6.04316,
     "end_time": "2022-10-27T07:55:29.096242",
     "exception": false,
     "start_time": "2022-10-27T07:55:23.053082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [00:01, 840.86it/s]\n",
      "859it [00:01, 858.32it/s]\n",
      "859it [00:01, 844.03it/s]\n",
      "859it [00:01, 688.82it/s]\n",
      "858it [00:01, 839.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    val_image_paths = val_image_paths_list[fold]\n",
    "    for i,image in tqdm(enumerate(val_image_paths)):\n",
    "        image_id = image.split('_')[0]\n",
    "        row = df[df['id']==image_id].iloc[0]\n",
    "        label = row.image_level\n",
    "        if label=='opacity':\n",
    "            bboxes = get_bbox(row)\n",
    "            scale_bboxes = scale_bbox(row,bboxes)\n",
    "            yolo_bboxes = get_yolo_format_bbox(SIZE,SIZE,scale_bboxes)\n",
    "            with (open(f'/kaggle/tmp/dataset/{fold}/labels/val/{image_id}.txt','w')) as file:\n",
    "                for bbox in yolo_bboxes:\n",
    "                    bbox = [0]+bbox\n",
    "                    bbox = [str(i) for i in bbox]\n",
    "                    bbox = ' '.join(bbox)\n",
    "                    file.write(bbox)\n",
    "                    file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d694f",
   "metadata": {
    "papermill": {
     "duration": 0.691107,
     "end_time": "2022-10-27T07:55:30.542249",
     "exception": false,
     "start_time": "2022-10-27T07:55:29.851142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Downloading YoloV5x Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4220adc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:55:31.986742Z",
     "iopub.status.busy": "2022-10-27T07:55:31.986391Z",
     "iopub.status.idle": "2022-10-27T07:56:09.376269Z",
     "shell.execute_reply": "2022-10-27T07:56:09.375308Z"
    },
    "papermill": {
     "duration": 38.756791,
     "end_time": "2022-10-27T07:56:10.045480",
     "exception": false,
     "start_time": "2022-10-27T07:55:31.288689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_109ou5qr_model:best, 165.05MB. 1 files... Done. 0:0:2.9\n",
      " 20%|██        | 1/5 [00:03<00:15,  3.89s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_1jbxg1v5_model:best, 165.05MB. 1 files... Done. 0:0:3.0\n",
      " 40%|████      | 2/5 [00:07<00:11,  3.98s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_16d7mbhm_model:best, 165.05MB. 1 files... Done. 0:0:3.0\n",
      " 60%|██████    | 3/5 [00:11<00:07,  4.00s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_31z85lql_model:best, 165.05MB. 1 files... Done. 0:0:14.9\n",
      " 80%|████████  | 4/5 [00:27<00:08,  8.71s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_2eh81g2f_model:best, 165.05MB. 1 files... Done. 0:0:8.3\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.48s/it]\n"
     ]
    }
   ],
   "source": [
    "yoloV5_dowloaded_weights = download_wandb_models(run,'YoloV5x',['run_109ou5qr_model:best',\n",
    "                                         'run_1jbxg1v5_model:best',\n",
    "                                         'run_16d7mbhm_model:best',\n",
    "                                         'run_31z85lql_model:best',\n",
    "                                         'run_2eh81g2f_model:best'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfedf969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T07:56:11.821482Z",
     "iopub.status.busy": "2022-10-27T07:56:11.821094Z",
     "iopub.status.idle": "2022-10-27T07:59:59.193427Z",
     "shell.execute_reply": "2022-10-27T07:59:59.192288Z"
    },
    "papermill": {
     "duration": 228.530855,
     "end_time": "2022-10-27T07:59:59.364559",
     "exception": false,
     "start_time": "2022-10-27T07:56:10.833704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/data/data_fold0.yaml, weights=['/kaggle/tmp/downloaded_models/YoloV5x/fold_0_best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/results/yoloV5_fold_0, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 23701ea Python-3.7.12 torch-1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\r\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\r\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 24.3MB/s]\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/tmp/dataset/0/labels/val' images and labels...859 found, \u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/tmp/dataset/0/labels/val.cache\r\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\r\n",
      "                   all        859       1580      0.579      0.541      0.539      0.173\r\n",
      "Speed: 0.2ms pre-process, 20.1ms inference, 1.3ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yoloV5_fold_0/exp\u001b[0m\r\n",
      "859 labels saved to /kaggle/working/results/yoloV5_fold_0/exp/labels\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/data/data_fold1.yaml, weights=['/kaggle/tmp/downloaded_models/YoloV5x/fold_1_best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/results/yoloV5_fold_1, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 23701ea Python-3.7.12 torch-1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/tmp/dataset/1/labels/val' images and labels...859 found, \u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/tmp/dataset/1/labels/val.cache\r\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\r\n",
      "                   all        859       1568      0.552      0.522      0.478      0.153\r\n",
      "Speed: 0.1ms pre-process, 19.7ms inference, 1.4ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yoloV5_fold_1/exp\u001b[0m\r\n",
      "859 labels saved to /kaggle/working/results/yoloV5_fold_1/exp/labels\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/data/data_fold2.yaml, weights=['/kaggle/tmp/downloaded_models/YoloV5x/fold_2_best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/results/yoloV5_fold_2, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 23701ea Python-3.7.12 torch-1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/tmp/dataset/2/labels/val' images and labels...859 found, \u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/tmp/dataset/2/labels/val.cache\r\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\r\n",
      "                   all        859       1574      0.603      0.529      0.537       0.18\r\n",
      "Speed: 0.1ms pre-process, 19.7ms inference, 1.3ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yoloV5_fold_2/exp\u001b[0m\r\n",
      "859 labels saved to /kaggle/working/results/yoloV5_fold_2/exp/labels\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/data/data_fold3.yaml, weights=['/kaggle/tmp/downloaded_models/YoloV5x/fold_3_best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/results/yoloV5_fold_3, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 23701ea Python-3.7.12 torch-1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/tmp/dataset/3/labels/val' images and labels...859 found, \u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/tmp/dataset/3/labels/val.cache\r\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\r\n",
      "                   all        859       1570      0.568      0.487      0.478      0.154\r\n",
      "Speed: 0.1ms pre-process, 19.9ms inference, 1.3ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yoloV5_fold_3/exp\u001b[0m\r\n",
      "859 labels saved to /kaggle/working/results/yoloV5_fold_3/exp/labels\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/data/data_fold4.yaml, weights=['/kaggle/tmp/downloaded_models/YoloV5x/fold_4_best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/results/yoloV5_fold_4, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 23701ea Python-3.7.12 torch-1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/tmp/dataset/4/labels/val' images and labels...858 found, \u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/tmp/dataset/4/labels/val.cache\r\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\r\n",
      "                   all        858       1561      0.563      0.522      0.517       0.17\r\n",
      "Speed: 0.2ms pre-process, 20.1ms inference, 1.2ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yoloV5_fold_4/exp\u001b[0m\r\n",
      "858 labels saved to /kaggle/working/results/yoloV5_fold_4/exp/labels\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/yolov5/val.py \\\n",
    "--weights /kaggle/tmp/downloaded_models/YoloV5x/fold_0_best.pt \\\n",
    "--data data_fold0.yaml\\\n",
    "--img 512\\\n",
    "--project /kaggle/working/results/yoloV5_fold_0\\\n",
    "--save-txt --save-conf\n",
    "\n",
    "!python /kaggle/working/yolov5/val.py \\\n",
    "--weights /kaggle/tmp/downloaded_models/YoloV5x/fold_1_best.pt \\\n",
    "--data data_fold1.yaml\\\n",
    "--img 512\\\n",
    "--project /kaggle/working/results/yoloV5_fold_1\\\n",
    "--save-txt --save-conf\n",
    "\n",
    "!python /kaggle/working/yolov5/val.py \\\n",
    "--weights /kaggle/tmp/downloaded_models/YoloV5x/fold_2_best.pt \\\n",
    "--data data_fold2.yaml\\\n",
    "--img 512\\\n",
    "--project /kaggle/working/results/yoloV5_fold_2\\\n",
    "--save-txt --save-conf\n",
    "\n",
    "!python /kaggle/working/yolov5/val.py \\\n",
    "--weights /kaggle/tmp/downloaded_models/YoloV5x/fold_3_best.pt \\\n",
    "--data data_fold3.yaml\\\n",
    "--img 512\\\n",
    "--project /kaggle/working/results/yoloV5_fold_3\\\n",
    "--save-txt --save-conf\n",
    "\n",
    "!python /kaggle/working/yolov5/val.py \\\n",
    "--weights /kaggle/tmp/downloaded_models/YoloV5x/fold_4_best.pt \\\n",
    "--data data_fold4.yaml\\\n",
    "--img 512\\\n",
    "--project /kaggle/working/results/yoloV5_fold_4\\\n",
    "--save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29c3a2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:00.913675Z",
     "iopub.status.busy": "2022-10-27T08:00:00.913275Z",
     "iopub.status.idle": "2022-10-27T08:00:00.984886Z",
     "shell.execute_reply": "2022-10-27T08:00:00.983970Z"
    },
    "papermill": {
     "duration": 0.849017,
     "end_time": "2022-10-27T08:00:00.987075",
     "exception": false,
     "start_time": "2022-10-27T08:00:00.138058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_translation_dict = {}\n",
    "for fold in range(5):\n",
    "    with open(f'/kaggle/working/coco_val_512x512_fold_{fold}.json','rb') as file:\n",
    "        val_ann_json = json.load(file)\n",
    "    for img_dict in val_ann_json['images']:\n",
    "        img_name = img_dict['file_name'].split('_')[0]\n",
    "        id_translation_dict[img_name] = img_dict['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "613000f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:02.738922Z",
     "iopub.status.busy": "2022-10-27T08:00:02.738546Z",
     "iopub.status.idle": "2022-10-27T08:00:02.757313Z",
     "shell.execute_reply": "2022-10-27T08:00:02.753436Z"
    },
    "papermill": {
     "duration": 0.984082,
     "end_time": "2022-10-27T08:00:02.760353",
     "exception": false,
     "start_time": "2022-10-27T08:00:01.776271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_txt_labels_to_json(label_path,out_json_path,size):\n",
    "    results = []\n",
    "    for i,label in enumerate(os.listdir(label_path)):\n",
    "        img_id = label.split('.')[0]\n",
    "        img_id = id_translation_dict[img_id]\n",
    "        with open(os.path.join(label_path,label),'r') as file:\n",
    "            for line in file.readlines():\n",
    "                line = line.strip()\n",
    "                ann = line.split(' ')\n",
    "                bbox = [float(x) for x in ann[1:5]]\n",
    "                yolo_bbox = yolo_to_coco_bbox(size,bbox)\n",
    "                conf = ann[5]\n",
    "                result_dict = dict(\n",
    "                    image_id=img_id,\n",
    "                    bbox=yolo_bbox,\n",
    "                    score=float(conf),\n",
    "                    category_id=0)\n",
    "                results.append(result_dict)\n",
    "    with open(out_json_path,'w') as file:\n",
    "        json.dump(results,file)\n",
    "    return results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e60dd4f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:04.260872Z",
     "iopub.status.busy": "2022-10-27T08:00:04.260511Z",
     "iopub.status.idle": "2022-10-27T08:00:05.222763Z",
     "shell.execute_reply": "2022-10-27T08:00:05.221685Z"
    },
    "papermill": {
     "duration": 1.741877,
     "end_time": "2022-10-27T08:00:05.225033",
     "exception": false,
     "start_time": "2022-10-27T08:00:03.483156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cascade_rcnn  retinanet      yoloV5_fold_1  yoloV5_fold_3\r\n",
      "faster_rcnn   yoloV5_fold_0  yoloV5_fold_2  yoloV5_fold_4\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93d43ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:06.737728Z",
     "iopub.status.busy": "2022-10-27T08:00:06.737330Z",
     "iopub.status.idle": "2022-10-27T08:00:15.297220Z",
     "shell.execute_reply": "2022-10-27T08:00:15.294321Z"
    },
    "papermill": {
     "duration": 9.289482,
     "end_time": "2022-10-27T08:00:15.301294",
     "exception": false,
     "start_time": "2022-10-27T08:00:06.011812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "yolo_results_json_path = ['/kaggle/working/results/yoloV5_fold_0/yoloV5_fold0.json',\n",
    "                         '/kaggle/working/results/yoloV5_fold_1/yoloV5_fold1.json',\n",
    "                         '/kaggle/working/results/yoloV5_fold_2/yoloV5_fold2.json',\n",
    "                         '/kaggle/working/results/yoloV5_fold_3/yoloV5_fold3.json',\n",
    "                         '/kaggle/working/results/yoloV5_fold_4/yoloV5_fold4.json',\n",
    "                        ]\n",
    "\n",
    "for fold in tqdm(range(5)):\n",
    "    yolo_txt_labels_to_json(f'/kaggle/working/results/yoloV5_fold_{fold}/exp/labels/',yolo_results_json_path[fold],512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ca727ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:17.250094Z",
     "iopub.status.busy": "2022-10-27T08:00:17.249666Z",
     "iopub.status.idle": "2022-10-27T08:00:46.548880Z",
     "shell.execute_reply": "2022-10-27T08:00:46.547850Z"
    },
    "papermill": {
     "duration": 30.43131,
     "end_time": "2022-10-27T08:00:46.551592",
     "exception": false,
     "start_time": "2022-10-27T08:00:16.120282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.75s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.99s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.73s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.537\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.64s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.60s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.66s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.66s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.54s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n"
     ]
    }
   ],
   "source": [
    "yoloV5_mAP50_list = []\n",
    "for fold in range(5):\n",
    "    cocoGt = COCO(f'/kaggle/working/coco_val_512x512_fold_{fold}.json')\n",
    "    cocoDt = cocoGt.loadRes(yolo_results_json_path[fold])\n",
    "    imgIds=sorted(cocoGt.getImgIds())\n",
    "    cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "\n",
    "    cocoEval.params.catIds = [0] \n",
    "    cocoEval.evaluate()  \n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    mAP50 = cocoEval.stats[1]\n",
    "    yoloV5_mAP50_list.append(mAP50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "034791bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:48.416046Z",
     "iopub.status.busy": "2022-10-27T08:00:48.415493Z",
     "iopub.status.idle": "2022-10-27T08:00:48.427017Z",
     "shell.execute_reply": "2022-10-27T08:00:48.426184Z"
    },
    "papermill": {
     "duration": 1.153904,
     "end_time": "2022-10-27T08:00:48.431108",
     "exception": false,
     "start_time": "2022-10-27T08:00:47.277204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508508931955668"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yoloV5_mAP50_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef33cb4",
   "metadata": {
    "papermill": {
     "duration": 0.774114,
     "end_time": "2022-10-27T08:00:50.082271",
     "exception": false,
     "start_time": "2022-10-27T08:00:49.308157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Uploading Visual Predictions to WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f7d65",
   "metadata": {
    "papermill": {
     "duration": 0.717641,
     "end_time": "2022-10-27T08:00:51.578188",
     "exception": false,
     "start_time": "2022-10-27T08:00:50.860547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "run = wandb.init(project=PROJECT_NAME,\n",
    "                 name=f'visualization_{EXP_NAME}',\n",
    "                 job_type='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bb69ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:53.086951Z",
     "iopub.status.busy": "2022-10-27T08:00:53.086595Z",
     "iopub.status.idle": "2022-10-27T08:00:53.099701Z",
     "shell.execute_reply": "2022-10-27T08:00:53.098780Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.74282,
     "end_time": "2022-10-27T08:00:53.101659",
     "exception": false,
     "start_time": "2022-10-27T08:00:52.358839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_images_to_wandb(imagepaths,model,results_list):\n",
    "    class_id_to_label = {\n",
    "        1: \"pred_covid_abnormality\",\n",
    "        2: \"GT_covid_abnormality\"\n",
    "    }\n",
    "\n",
    "    wnb_images = []\n",
    "\n",
    "    for img_id, result in zip(imagepaths, results_list):\n",
    "\n",
    "        image = cv2.imread(os.path.join(imgs_path, img_id))\n",
    "        im_size = image.shape[0]\n",
    "        bboxes = result[:, :4]\n",
    "        scores = result[:, 4]\n",
    "        ann_dict = {\"predictions\":{\n",
    "                            \"box_data\":[],\n",
    "                            \"class_labels\": class_id_to_label\n",
    "                            },\n",
    "                    \"ground_truth\":{\n",
    "                            \"box_data\":[],\n",
    "                            \"class_labels\": class_id_to_label\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "        for box, score in zip(bboxes, scores):\n",
    "            single_data = {\n",
    "                # one box expressed in the default relative/fractional domain\n",
    "                \"position\": {\n",
    "                    \"minX\": round(float(box[0])/im_size, 3),\n",
    "                    \"maxX\": round(float(box[2])/im_size, 3),\n",
    "                    \"minY\": round(float(box[1])/im_size, 3),\n",
    "                    \"maxY\": round(float(box[3])/im_size, 3),\n",
    "                },\n",
    "                \"class_id\" : 1,\n",
    "                \"box_caption\": class_id_to_label[1],\n",
    "                \"scores\" : {\n",
    "                    \"confidence\": float(score),\n",
    "                }\n",
    "            }\n",
    "            ann_dict[\"predictions\"][\"box_data\"].append(single_data)\n",
    "\n",
    "        image_annotations = df_annotations[df_annotations.id==img_id.strip('.png')]\n",
    "\n",
    "        for idxx, row in image_annotations[['xmin', 'ymin', 'xmax', 'ymax']].iterrows():\n",
    "            single_data = {\n",
    "                # one box expressed in the default relative/fractional domain\n",
    "                \"position\": {\n",
    "                    \"minX\": round(float(row[0])/im_size, 3),\n",
    "                    \"maxX\": round(float(row[2])/im_size, 3),\n",
    "                    \"minY\": round(float(row[1])/im_size, 3),\n",
    "                    \"maxY\": round(float(row[3])/im_size, 3),\n",
    "                },\n",
    "                \"class_id\" : 2,# Class id 2 is used to denote ground truth\n",
    "                \"box_caption\": class_id_to_label[2],\n",
    "                \"scores\" : {\n",
    "                    \"confidence\": 1.0,\n",
    "                }\n",
    "            }\n",
    "            ann_dict[\"ground_truth\"][\"box_data\"].append(single_data)\n",
    "\n",
    "        wnb_images.append(wandb.Image(image, boxes=ann_dict,caption=img_id))\n",
    "\n",
    "    wandb.log({f'images-{model}': wnb_images})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58330c09",
   "metadata": {
    "papermill": {
     "duration": 0.717819,
     "end_time": "2022-10-27T08:00:54.603048",
     "exception": false,
     "start_time": "2022-10-27T08:00:53.885229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "imgs_path = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_512x512'\n",
    "with open(val_ann_file) as file:\n",
    "    val_ann = json.load(file)\n",
    "imagepaths = [item['file_name'] for item in val_ann['images'][:]]\n",
    "\n",
    "df_annotations = pd.read_csv('/kaggle/input/siim-covid19-512-images-and-metadata/df_train_processed_meta.csv')\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for idx, img_id in tqdm(enumerate(imagepaths)):\n",
    "    img_path = os.path.join(imgs_path, img_id)\n",
    "    img = cv2.imread(img_path)\n",
    "    result = inference_detector(retinanet, img_path)\n",
    "    results_list.append(result[0])\n",
    "\n",
    "upload_images_to_wandb(imagepaths,'RetinaNet',results_list)\n",
    "\n",
    "for idx, img_id in tqdm(enumerate(imagepaths)):\n",
    "    img_path = os.path.join(imgs_path, img_id)\n",
    "    img = cv2.imread(img_path)\n",
    "    result = inference_detector(cascade_rcnn, img_path)\n",
    "    results_list.append(result[0])\n",
    "\n",
    "upload_images_to_wandb(imagepaths,'Cascade RCNN',results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e26c0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T08:00:56.118153Z",
     "iopub.status.busy": "2022-10-27T08:00:56.117765Z",
     "iopub.status.idle": "2022-10-27T08:00:59.263294Z",
     "shell.execute_reply": "2022-10-27T08:00:59.262399Z"
    },
    "papermill": {
     "duration": 3.931992,
     "end_time": "2022-10-27T08:00:59.265241",
     "exception": false,
     "start_time": "2022-10-27T08:00:55.333249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f735e21081c0491e9f72d27a5e9298ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">Inference_27/10_08:43</strong>: <a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/29xqh48m\" target=\"_blank\">https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/29xqh48m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221027_064332-29xqh48m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2374ca0",
   "metadata": {
    "papermill": {
     "duration": 0.741719,
     "end_time": "2022-10-27T08:01:00.797120",
     "exception": false,
     "start_time": "2022-10-27T08:01:00.055401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4944.377209,
   "end_time": "2022-10-27T08:01:04.213420",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-27T06:38:39.836211",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1031c6532206401e861fe65bce4b8e48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9949ee6ebd2648de84a550b90f0b50eb",
       "placeholder": "​",
       "style": "IPY_MODEL_9cbfa17ada284da2877cb38fa8049eba",
       "value": "0.094 MB of 0.094 MB uploaded (0.000 MB deduped)\r"
      }
     },
     "1cffd898bdb242d2bcfa9b3aa5511b45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38a8cb77733543b6bcaa3e6faed6813a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53ba53c8a5c844a88722e8bc6a946613": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e7350e876dda4078a13d82e835700424",
       "placeholder": "​",
       "style": "IPY_MODEL_f6c9dfb831b34c35ba3eea8fe7db43b0",
       "value": ""
      }
     },
     "5bfa8d12adac43078f0385589ae305b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_53ba53c8a5c844a88722e8bc6a946613",
        "IPY_MODEL_8c9b0529985c43fd9673378c54270a30"
       ],
       "layout": "IPY_MODEL_ad2fe916e39f4512ab042d033576193c"
      }
     },
     "7fc6ca0de804415ca774f6650201d59f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8c9b0529985c43fd9673378c54270a30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ddf8e3fa94e8459daaa41ea6f7bfb2ad",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1cffd898bdb242d2bcfa9b3aa5511b45",
       "value": 0
      }
     },
     "9949ee6ebd2648de84a550b90f0b50eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cbfa17ada284da2877cb38fa8049eba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ad2fe916e39f4512ab042d033576193c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad39c8bd5d8b47608599c3b5e24a0ecc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_38a8cb77733543b6bcaa3e6faed6813a",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7fc6ca0de804415ca774f6650201d59f",
       "value": 1
      }
     },
     "ddf8e3fa94e8459daaa41ea6f7bfb2ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e49385d8638f443fbcf26437147766a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7350e876dda4078a13d82e835700424": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6c9dfb831b34c35ba3eea8fe7db43b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f735e21081c0491e9f72d27a5e9298ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1031c6532206401e861fe65bce4b8e48",
        "IPY_MODEL_ad39c8bd5d8b47608599c3b5e24a0ecc"
       ],
       "layout": "IPY_MODEL_e49385d8638f443fbcf26437147766a5"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
