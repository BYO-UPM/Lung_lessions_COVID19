{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:39:42.601485Z","iopub.status.busy":"2022-10-01T18:39:42.601110Z","iopub.status.idle":"2022-10-01T18:40:07.352301Z","shell.execute_reply":"2022-10-01T18:40:07.351167Z","shell.execute_reply.started":"2022-10-01T18:39:42.601456Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["gdcm/\n","gdcm/conda-4.8.4-py37hc8dfbb8_2.tar.bz2\n","gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n","gdcm/libjpeg-turbo-2.0.3-h516909a_1.tar.bz2\n","\n","Downloading and Extracting Packages\n","######################################################################## | 100% \n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n"]}],"source":["!cp /kaggle/input/gdcm-conda-install/gdcm.tar .\n","!tar -xvzf gdcm.tar\n","!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n","!rm -rf ./gdcm.tar"]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:07.355051Z","iopub.status.busy":"2022-10-01T18:40:07.354654Z","iopub.status.idle":"2022-10-01T18:40:09.118458Z","shell.execute_reply":"2022-10-01T18:40:09.117240Z","shell.execute_reply.started":"2022-10-01T18:40:07.355013Z"},"trusted":true},"outputs":[],"source":["import os\n","import ast\n","import numpy as np\n","import pandas as pd\n","from path import Path\n","import datetime\n","import glob\n","import json\n","import shutil\n","import random\n","from PIL import Image\n","from tqdm.auto import tqdm\n","import pydicom\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","import wandb\n","from sklearn.model_selection import train_test_split\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:09.120285Z","iopub.status.busy":"2022-10-01T18:40:09.119938Z","iopub.status.idle":"2022-10-01T18:40:12.259511Z","shell.execute_reply":"2022-10-01T18:40:12.258668Z","shell.execute_reply.started":"2022-10-01T18:40:09.120251Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from kaggle_secrets import UserSecretsClient\n","\n","user_secrets = UserSecretsClient()\n","wandb_api = user_secrets.get_secret(\"wandb-key\") \n","wandb.login(key=wandb_api,relogin=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:12.261901Z","iopub.status.busy":"2022-10-01T18:40:12.261536Z","iopub.status.idle":"2022-10-01T18:40:19.799467Z","shell.execute_reply":"2022-10-01T18:40:19.798393Z","shell.execute_reply.started":"2022-10-01T18:40:12.261871Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malvaromoureupm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.12.16"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20221001_184012-wttp2bgf</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/wttp2bgf\" target=\"_blank\">various_sizes_train_test_coco_file_generation</a></strong> to <a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["run = wandb.init(project='Final-Covid19-Detection',\n","                 name='various_sizes_train_test_coco_file_generation',\n","                job_type='split_file_generation',\n","                notes='Generation of a single artifact containing all different sizes annotation files')"]},{"cell_type":"markdown","metadata":{},"source":["# Paths Definition"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:19.802649Z","iopub.status.busy":"2022-10-01T18:40:19.801868Z","iopub.status.idle":"2022-10-01T18:40:19.809031Z","shell.execute_reply":"2022-10-01T18:40:19.808139Z","shell.execute_reply.started":"2022-10-01T18:40:19.802596Z"},"trusted":true},"outputs":[],"source":["SEED = 42"]},{"cell_type":"markdown","metadata":{},"source":["## Duplicate images without bounding boxes"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:19.811489Z","iopub.status.busy":"2022-10-01T18:40:19.810811Z","iopub.status.idle":"2022-10-01T18:40:19.991376Z","shell.execute_reply":"2022-10-01T18:40:19.990309Z","shell.execute_reply.started":"2022-10-01T18:40:19.811445Z"},"trusted":true},"outputs":[],"source":["image_level_df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\n","study_level_df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\n","study_level_df['StudyInstanceUID'] = study_level_df['id'].apply(lambda x: x.replace('_study',''))\n","study_level_df.drop('id',axis=1,inplace=True)\n","train_df = image_level_df.merge(study_level_df,on='StudyInstanceUID')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:42:22.370921Z","iopub.status.busy":"2022-10-01T18:42:22.370517Z","iopub.status.idle":"2022-10-01T18:42:28.200172Z","shell.execute_reply":"2022-10-01T18:42:28.197806Z","shell.execute_reply.started":"2022-10-01T18:42:22.370890Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9c3cfe252564edda1b04f63cf3360f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6054 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["image_ids = []\n","for study_id in tqdm(set(train_df['StudyInstanceUID'])):\n","    study_df = train_df[train_df['StudyInstanceUID']==study_id]\n","    imgs_to_append = []\n","\n","    if len(study_df) == 1:\n","    # if study only contains one image, append it\n","        imgs_to_append.append(study_df['id'].values.tolist())\n","\n","    else:\n","        rows = study_df[study_df['label'] != 'none 1 0 0 1 1']['id']\n","        if len(rows) >= 1:\n","    # If study contains more that one image with bounding boxes, append the images with bounding boxes (discarding those w/bboxes)\n","            imgs_to_append.append(rows.values.tolist())\n","        elif len(rows) == 0:\n","    # If study contains more that one image, all of them without bounding boxes, append those images\n","            imgs_to_append.append(study_df[study_df['label'] == 'none 1 0 0 1 1']['id'].values.tolist())\n","    for img in imgs_to_append[0]:\n","        image_ids.append(img)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:42:28.202638Z","iopub.status.busy":"2022-10-01T18:42:28.201990Z","iopub.status.idle":"2022-10-01T18:42:28.215302Z","shell.execute_reply":"2022-10-01T18:42:28.213599Z","shell.execute_reply.started":"2022-10-01T18:42:28.202606Z"},"trusted":true},"outputs":[{"data":{"text/plain":["6117"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(image_ids) "]},{"cell_type":"markdown","metadata":{},"source":["# Resizing Images "]},{"cell_type":"markdown","metadata":{},"source":["### Util Functions"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:19.993219Z","iopub.status.busy":"2022-10-01T18:40:19.992809Z","iopub.status.idle":"2022-10-01T18:40:20.015405Z","shell.execute_reply":"2022-10-01T18:40:20.014051Z","shell.execute_reply.started":"2022-10-01T18:40:19.993178Z"},"trusted":true},"outputs":[],"source":["from pydicom.pixel_data_handlers.util import apply_voi_lut\n","\n","def read_xray(path, voi_lut = True, fix_monochrome = True):\n","    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n","    dicom = pydicom.read_file(path)\n","    if voi_lut:\n","        data = apply_voi_lut(dicom.pixel_array, dicom)\n","    else:\n","        data = dicom.pixel_array           \n","    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n","        data = np.amax(data) - data \n","    data = data - np.min(data) \n","    data = data / np.max(data) \n","    data = (data * 255).astype(np.uint8)    \n","    return data\n","\n","def get_image_metadata(study_id, df):\n","    data = df[df[\"id\"] == study_id]\n","    \n","    if data[\"Negative for Pneumonia\"].values == 1:\n","        label = \"negative_for_pneumonia\"\n","        label = \"Negative for Pneumonia\"\n","    elif data[\"Typical Appearance\"].values == 1:\n","        label = \"typical\"\n","        label = \"Typical Appearance\"\n","    elif data[\"Indeterminate Appearance\"].values == 1:\n","        label = \"indeterminate\"\n","        label = \"Indeterminate Appearance\"\n","    else:\n","        label = \"atypical\"\n","        label = 'Atypical Appearance'\n","        \n","    bboxes = list(data[\"boxes\"].values)\n","    \n","    return label, bboxes\n","\n","def get_box_cords(box):\n","    x1,y1,x2,y2 = box['x'],box['y'], box['x'] + box['width'], box['y'] + box['height']\n","    return (int(x1),int(y1),int(x2),int(y2))\n","\n","def scale_bbox(img, bboxes,img_size):\n","    # Get scaling factor\n","    scale_x = img.shape[0]/img_size[0]\n","    scale_y = img.shape[1]/img_size[1]\n","    \n","    scaled_bboxes = []\n","    for bbox in bboxes:\n","        x = int(np.round(bbox[0]/scale_y, 4))\n","        y = int(np.round(bbox[1]/scale_x, 4))\n","        x1 = int(np.round(bbox[2]/scale_y, 4))\n","        y1= int(np.round(bbox[3]/scale_x, 4))\n","\n","        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n","        \n","    return scaled_bboxes\n","    "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:40:20.017460Z","iopub.status.busy":"2022-10-01T18:40:20.017022Z","iopub.status.idle":"2022-10-01T18:40:20.029729Z","shell.execute_reply":"2022-10-01T18:40:20.028692Z","shell.execute_reply.started":"2022-10-01T18:40:20.017417Z"},"trusted":true},"outputs":[],"source":["images_folder = '/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768'\n","os.makedirs(images_folder, exist_ok=True)\n","\n","# Define sizes\n","new_sizes = [(256,256),(512,512),(768,768)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-18T15:55:02.640503Z","iopub.status.busy":"2022-09-18T15:55:02.640154Z","iopub.status.idle":"2022-09-18T18:44:49.809021Z","shell.execute_reply":"2022-09-18T18:44:49.808061Z","shell.execute_reply.started":"2022-09-18T15:55:02.640471Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 64-bit' requires ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["for new_size in new_sizes:\n","    print(new_size)\n","    for split in ['train']:\n","    # for split in ['test']:\n","        save_dir = f'{images_folder}/{split}_{new_size[0]}x{new_size[1]}/'\n","        dcm_paths = glob.glob(f'/kaggle/input/siim-covid19-detection/{split}/*/*/*')\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        image_ids = []\n","        folder_ids = []\n","        study_ids = []\n","        widths = []\n","        heights = []\n","\n","        for path in tqdm(dcm_paths):\n","            # set keep_ratio=True to have original aspect ratio\n","            xray = read_xray(path)\n","            im = cv2.resize(xray,new_size)\n","\n","            path_split = path.split('/')\n","            study_id = path_split[-3]\n","            folder_id = path_split[-2]\n","            image_name = path_split[-1].replace('.dcm', '_image')\n","\n","            cv2.imwrite(os.path.join(save_dir, image_name+'.png'),im)\n","\n","            image_ids.append(image_name)\n","            folder_ids.append(folder_id)\n","            study_ids.append(study_id)\n","            widths.append(xray.shape[1])\n","            heights.append(xray.shape[0])\n","            \n","        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,\n","                                     'study_id': study_ids, 'width': widths,\n","                                     'height': heights})\n","        df.to_csv(f'{images_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Resizing Bounding Boxes (pipeline)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-18T18:44:49.811478Z","iopub.status.busy":"2022-09-18T18:44:49.811211Z","iopub.status.idle":"2022-09-18T18:45:42.464716Z","shell.execute_reply":"2022-09-18T18:45:42.463468Z","shell.execute_reply.started":"2022-09-18T18:44:49.811451Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["*****(256, 256)*****\n","\n","Number of Images with Covid_Abnormality: 4294\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>4d47bc042ee6</td>\n","      <td>28dddc8559b2</td>\n","      <td>4280</td>\n","      <td>3520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  \\\n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n","2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n","3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n","\n","      folder_id      study_id  width  height  \n","0  81456c9c5423  5776db0cec75   4256    3488  \n","2  22897cd1daa0  9d514ce429a7   3056    2544  \n","3  4d47bc042ee6  28dddc8559b2   4280    3520  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ab6d9e7174a44dbb898037fac2cf4a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>47</td>\n","      <td>43</td>\n","      <td>109</td>\n","      <td>183</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>135</td>\n","      <td>43</td>\n","      <td>201</td>\n","      <td>173</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","      <td>57</td>\n","      <td>20</td>\n","      <td>129</td>\n","      <td>121</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id StudyInstanceUID     folder_id      study_id  width  \\\n","0  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","1  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","2  0012ff7358bc_image     9d514ce429a7  22897cd1daa0  9d514ce429a7   3056   \n","\n","   height  xmin  ymin  xmax  ymax  \n","0    3488    47    43   109   183  \n","1    3488   135    43   201   173  \n","2    2544    57    20   129   121  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","*****(512, 512)*****\n","\n","Number of Images with Covid_Abnormality: 4294\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>4d47bc042ee6</td>\n","      <td>28dddc8559b2</td>\n","      <td>4280</td>\n","      <td>3520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  \\\n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n","2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n","3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n","\n","      folder_id      study_id  width  height  \n","0  81456c9c5423  5776db0cec75   4256    3488  \n","2  22897cd1daa0  9d514ce429a7   3056    2544  \n","3  4d47bc042ee6  28dddc8559b2   4280    3520  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"edef7eec3b91463cbcdda65015dc8917","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>95</td>\n","      <td>85</td>\n","      <td>218</td>\n","      <td>367</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>270</td>\n","      <td>87</td>\n","      <td>402</td>\n","      <td>345</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","      <td>113</td>\n","      <td>40</td>\n","      <td>259</td>\n","      <td>241</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id StudyInstanceUID     folder_id      study_id  width  \\\n","0  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","1  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","2  0012ff7358bc_image     9d514ce429a7  22897cd1daa0  9d514ce429a7   3056   \n","\n","   height  xmin  ymin  xmax  ymax  \n","0    3488    95    85   218   367  \n","1    3488   270    87   402   345  \n","2    2544   113    40   259   241  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","*****(768, 768)*****\n","\n","Number of Images with Covid_Abnormality: 4294\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>4d47bc042ee6</td>\n","      <td>28dddc8559b2</td>\n","      <td>4280</td>\n","      <td>3520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  \\\n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n","2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n","3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n","\n","      folder_id      study_id  width  height  \n","0  81456c9c5423  5776db0cec75   4256    3488  \n","2  22897cd1daa0  9d514ce429a7   3056    2544  \n","3  4d47bc042ee6  28dddc8559b2   4280    3520  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6106fd1a633244b8b7b6827301381e0c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>142</td>\n","      <td>128</td>\n","      <td>328</td>\n","      <td>550</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>405</td>\n","      <td>130</td>\n","      <td>603</td>\n","      <td>518</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","      <td>170</td>\n","      <td>60</td>\n","      <td>388</td>\n","      <td>362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id StudyInstanceUID     folder_id      study_id  width  \\\n","0  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","1  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","2  0012ff7358bc_image     9d514ce429a7  22897cd1daa0  9d514ce429a7   3056   \n","\n","   height  xmin  ymin  xmax  ymax  \n","0    3488   142   128   328   550  \n","1    3488   405   130   603   518  \n","2    2544   170    60   388   362  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","*****(1024, 1024)*****\n","\n","Number of Images with Covid_Abnormality: 4294\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>4d47bc042ee6</td>\n","      <td>28dddc8559b2</td>\n","      <td>4280</td>\n","      <td>3520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  \\\n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n","2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n","3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n","\n","      folder_id      study_id  width  height  \n","0  81456c9c5423  5776db0cec75   4256    3488  \n","2  22897cd1daa0  9d514ce429a7   3056    2544  \n","3  4d47bc042ee6  28dddc8559b2   4280    3520  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e583924ddf54cbf8c473ac07998f430","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>190</td>\n","      <td>171</td>\n","      <td>437</td>\n","      <td>734</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>540</td>\n","      <td>174</td>\n","      <td>804</td>\n","      <td>691</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","      <td>227</td>\n","      <td>80</td>\n","      <td>518</td>\n","      <td>482</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id StudyInstanceUID     folder_id      study_id  width  \\\n","0  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","1  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","2  0012ff7358bc_image     9d514ce429a7  22897cd1daa0  9d514ce429a7   3056   \n","\n","   height  xmin  ymin  xmax  ymax  \n","0    3488   190   171   437   734  \n","1    3488   540   174   804   691  \n","2    2544   227    80   518   482  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","*****(1280, 1280)*****\n","\n","Number of Images with Covid_Abnormality: 4294\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>4d47bc042ee6</td>\n","      <td>28dddc8559b2</td>\n","      <td>4280</td>\n","      <td>3520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  \\\n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n","2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n","3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n","\n","      folder_id      study_id  width  height  \n","0  81456c9c5423  5776db0cec75   4256    3488  \n","2  22897cd1daa0  9d514ce429a7   3056    2544  \n","3  4d47bc042ee6  28dddc8559b2   4280    3520  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42f1881dca3843f38252b5cfaa249c9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>StudyInstanceUID</th>\n","      <th>folder_id</th>\n","      <th>study_id</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>237</td>\n","      <td>214</td>\n","      <td>546</td>\n","      <td>917</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000a312787f2_image</td>\n","      <td>5776db0cec75</td>\n","      <td>81456c9c5423</td>\n","      <td>5776db0cec75</td>\n","      <td>4256</td>\n","      <td>3488</td>\n","      <td>675</td>\n","      <td>217</td>\n","      <td>1005</td>\n","      <td>863</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>9d514ce429a7</td>\n","      <td>22897cd1daa0</td>\n","      <td>9d514ce429a7</td>\n","      <td>3056</td>\n","      <td>2544</td>\n","      <td>284</td>\n","      <td>100</td>\n","      <td>647</td>\n","      <td>603</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id StudyInstanceUID     folder_id      study_id  width  \\\n","0  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","1  000a312787f2_image     5776db0cec75  81456c9c5423  5776db0cec75   4256   \n","2  0012ff7358bc_image     9d514ce429a7  22897cd1daa0  9d514ce429a7   3056   \n","\n","   height  xmin  ymin  xmax  ymax  \n","0    3488   237   214   546   917  \n","1    3488   675   217  1005   863  \n","2    2544   284   100   647   603  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["for new_size in new_sizes:\n","    print(f\"*****{new_size}*****\\n\")\n","    df_train_meta = pd.read_csv(f'{images_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')\n","    # Comment to use the df_train without duplicate bounding boxes\n","    df_train = pd.read_csv(\"/kaggle/input/siim-covid19-detection/train_image_level.csv\")\n","    df_train_meta = df_train.merge(df_train_meta, on='id')\n","    \n","    #\n","    #df_train_meta = df_train_meta.dropna() # Drop all rows of images without annotations\n","    imagepaths = df_train_meta.id.unique()\n","    print(\"Number of Images with Covid_Abnormality:\",len(imagepaths))\n","    \n","    display(df_train_meta.head(3))\n","    print()\n","    \n","    df_idx=0\n","\n","    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):\n","        img = cv2.imread(os.path.join(f\"/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/\",\n","                                      row.id.replace(\"_image\", \".png\")))\n","        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]\n","        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)\n","\n","        for box in bboxes:\n","            box[2] = box[2]+box[0]\n","            box[3] = box[3]+box[1]\n","            box = (box[0]*width_ratio, box[1]*height_ratio,\n","                   box[2]*width_ratio, box[3]*height_ratio)\n","\n","            row_df = pd.DataFrame({'id':row.id,\n","                           'StudyInstanceUID':row.StudyInstanceUID,\n","                           'folder_id':row.folder_id,\n","                           'study_id':row.study_id,\n","                           'width':row.width,\n","                           'height':row.height,\n","                           'xmin':round(box[0]),\n","                           'ymin':round(box[1]),\n","                           'xmax':round(box[2]),\n","                           'ymax':round(box[3])}, index=[df_idx])\n","\n","            if df_idx==0:\n","                df_train_processed = row_df\n","            else:\n","                df_train_processed = pd.concat([df_train_processed, row_df])\n","\n","            df_idx+=1\n","\n","    display(df_train_processed.head(3))\n","    print()\n","    df_train_processed.to_csv(f'{images_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',\n","                              index=False)\n","    df_train_processed.shape"]},{"cell_type":"markdown","metadata":{},"source":["# COCO Dataset Style Generation"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:41:43.069906Z","iopub.status.busy":"2022-10-01T18:41:43.069591Z","iopub.status.idle":"2022-10-01T18:41:43.079726Z","shell.execute_reply":"2022-10-01T18:41:43.078777Z","shell.execute_reply.started":"2022-10-01T18:41:43.069878Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'info': {'description': 'SIIM Covid 19 Train',\n","  'url': None,\n","  'version': 1,\n","  'year': 2022,\n","  'contributor': None,\n","  'date_created': '2022-10-01 18:41:43.073130'},\n"," 'licenses': [{'url': None, 'id': 0, 'name': None}],\n"," 'images': [],\n"," 'type': 'instances',\n"," 'annotations': [],\n"," 'categories': [{'id': 1, 'name': 'Covid_Opacity'}]}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["now = datetime.datetime.now()\n","data = dict(\n","    info=dict(\n","        description='SIIM Covid 19 Train',\n","        url=None,\n","        version=1,\n","        year=now.year,\n","        contributor=None,\n","        date_created=now.strftime('%Y-%m-%d %H:%M:%S.%f')\n","        ),\n","    licenses=[dict(\n","        url=None,\n","        id=0,\n","        name=None)],\n","    images = [],\n","    type='instances',\n","    annotations=[],\n","    categories=[dict(\n","        id=1,\n","        name='Covid_Opacity')],\n",")\n","data"]},{"cell_type":"markdown","metadata":{},"source":["## Train/Val Spliting"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:42:30.368412Z","iopub.status.busy":"2022-10-01T18:42:30.367384Z","iopub.status.idle":"2022-10-01T18:42:30.418335Z","shell.execute_reply":"2022-10-01T18:42:30.417368Z","shell.execute_reply.started":"2022-10-01T18:42:30.368369Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original image level size: 6334\n","Size of df after removing duplicates: 6117\n"]},{"data":{"text/plain":["train    5505\n","val       612\n","Name: split, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#df = pd.read_csv(f'/kaggle/input/siim-covid19-images-metadata-256-512-768/images_metadata_256_512_768/train_meta_{SIZE}x{SIZE}.csv')\n","#df['id'] = df['id'].apply(lambda x: x.split('_')[0])\n","df = pd.read_csv(\"/kaggle/input/siim-covid19-detection/train_image_level.csv\")\n","print(f'Original image level size: {len(df)}')\n","#df = df[df.label!='none 1 0 0 1 1'] # discard images without boundinx boxes\n","df = df[df['id'].isin(image_ids)]\n","print(f'Size of df after removing duplicates: {len(df)}')\n","train_df,val_df = train_test_split(df,train_size=0.9,random_state=SEED)\n","train_df['split'] = 'train'\n","train_df\n","val_df['split'] = 'val'\n","df = pd.concat([train_df,val_df])\n","df['split'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Training/Validation Annotation File Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:49:00.169952Z","iopub.status.busy":"2022-10-01T18:49:00.169270Z","iopub.status.idle":"2022-10-01T18:49:46.563507Z","shell.execute_reply":"2022-10-01T18:49:46.562585Z","shell.execute_reply.started":"2022-10-01T18:49:00.169915Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 64-bit' requires ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["for size in new_sizes:\n","    print(f'Creating json annotation file for size {size}')\n","    size = size[0]\n","    train_ids = train_df['id'].unique()\n","    val_ids = val_df['id'].unique()\n","    print(f'Train images: {len(train_ids)} \\n Validation images: {len(val_ids)}')\n","    df_annotations = pd.read_csv(f'{images_folder}/df_train_processed_meta_{size}x{size}.csv')\n","    out_train_json = f'coco_train_{size}x{size}.json'\n","    out_val_json = f'coco_val_{size}x{size}.json'\n","    data_train = data.copy()\n","    data_train['images'] = []\n","    data_train['annotations'] = []\n","    data_val = data.copy()\n","    data_val['images'] = []\n","    data_val['annotations'] = []\n","    \n","    # Train annotations file loop\n","    for i,img_id in enumerate(tqdm(train_ids)):\n","        data_train['images'].append(\n","            dict(\n","                license=0,\n","                url=None,\n","                file_name=img_id+'.png',\n","                height=size,\n","                width=size,\n","                date_captured=None,\n","                id=i\n","            )\n","        )\n","        img_annotations = df_annotations[df_annotations['id']==img_id]\n","        if len(img_annotations) > 0:\n","            boxes = img_annotations[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n","            box_labels = np.zeros(img_annotations.shape[0])\n","            for box,label in zip(boxes,box_labels):\n","                x1,y1,x2,y2 = (box[0],box[1],box[2],box[3])\n","                area = round((x2-x1)*(y2-y1),1)\n","                bbox=[\n","                    int(x1),\n","                    int(y1),\n","                    int(x2-x1),\n","                    int(y2-y1)\n","                ]\n","                data_train['annotations'].append(\n","                    dict(\n","                    id=len(data_train['annotations']),\n","                    image_id=i,\n","                    category_id=int(label),\n","                    area=int(area),\n","                    bbox=bbox,\n","                    segmentation=[],\n","                    iscrowd=0)\n","                )\n","    with open(os.path.join('/kaggle/working',out_train_json),'w') as fp:\n","                json.dump(data_train,fp,indent=4)\n","            \n","    # Validation annotations loop\n","    \n","    for i,img_id in enumerate(tqdm(val_ids)):\n","        data_val['images'].append(\n","            dict(\n","                license=0,\n","                url=None,\n","                file_name=img_id+'.png',\n","                height=size,\n","                width=size,\n","                date_captured=None,\n","                id=i\n","            )\n","        )\n","        img_annotations = df_annotations[df_annotations['id']==img_id]\n","        if len(img_annotations) > 0:\n","            boxes = img_annotations[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n","            box_labels = np.zeros(img_annotations.shape[0])\n","            for box,label in zip(boxes,box_labels):\n","                x1,y1,x2,y2 = (box[0],box[1],box[2],box[3])\n","                area = round((x2-x1)*(y2-y1),1)\n","                bbox=[\n","                    int(x1),\n","                    int(y1),\n","                    int(x2-x1),\n","                    int(y2-y1)\n","                ]\n","                data_val['annotations'].append(\n","                    dict(\n","                    id=len(data_val['annotations']),\n","                    image_id=i,\n","                    category_id=int(label),\n","                    area=int(area),\n","                    bbox=bbox,\n","                    segmentation=[],\n","                    iscrowd=0)\n","                )\n","    with open(os.path.join('/kaggle/working',out_val_json),'w') as fp:\n","                json.dump(data_val,fp,indent=4)\n","\n","               "]},{"cell_type":"markdown","metadata":{},"source":["### Wandb Upload of the split files"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-10-01T18:49:51.642124Z","iopub.status.busy":"2022-10-01T18:49:51.641704Z","iopub.status.idle":"2022-10-01T18:49:56.199287Z","shell.execute_reply":"2022-10-01T18:49:56.198153Z","shell.execute_reply.started":"2022-10-01T18:49:51.642089Z"},"trusted":true},"outputs":[{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='18.360 MB of 18.360 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">various_sizes_train_test_coco_file_generation</strong>: <a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/wttp2bgf\" target=\"_blank\">https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/wttp2bgf</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20221001_184012-wttp2bgf/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## K-Fold"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T16:15:06.876172Z","iopub.status.busy":"2022-08-23T16:15:06.875666Z","iopub.status.idle":"2022-08-23T16:15:06.982908Z","shell.execute_reply":"2022-08-23T16:15:06.982178Z","shell.execute_reply.started":"2022-08-23T16:15:06.876133Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape before removing images without bboxes: (6334, 4)\n","Shape after removing images without bboxes: (4294, 4)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>boxes</th>\n","      <th>label</th>\n","      <th>StudyInstanceUID</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000a312787f2_image</td>\n","      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n","      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n","      <td>5776db0cec75</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0012ff7358bc_image</td>\n","      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n","      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n","      <td>9d514ce429a7</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>001398f4ff4f_image</td>\n","      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n","      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n","      <td>28dddc8559b2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id                                              boxes  \\\n","0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n","1  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n","2  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n","\n","                                               label StudyInstanceUID  fold  \n","0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75     4  \n","1  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7     2  \n","2    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2     2  "]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.model_selection import GroupKFold, train_test_split\n","\n","# Remove images without bboxes\n","df_kfold = pd.DataFrame(pd.read_csv(\"/kaggle/input/siim-covid19-detection/train_image_level.csv\"))\n","print(\"Shape before removing images without bboxes:\", df_kfold.shape)\n","df_kfold = (df_kfold[df_kfold.label!='none 1 0 0 1 1']).reset_index(drop=True)\n","print(\"Shape after removing images without bboxes:\", df_kfold.shape)\n","\n","kfold = 5\n","df_kfold['fold'] = -1\n","group_kfold  = GroupKFold(n_splits = kfold)\n","\n","for fold, (train_index, val_index) in enumerate(group_kfold.split(df_kfold,\n","                                                              groups=df_kfold.StudyInstanceUID.tolist())):\n","    df_kfold.loc[val_index, 'fold'] = fold\n","    \n","display(df_kfold.head(3))\n","df_kfold.to_csv(\"/kaggle/working/df_meta_kfold.csv\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T16:15:38.319243Z","iopub.status.busy":"2022-08-23T16:15:38.318825Z","iopub.status.idle":"2022-08-23T16:15:38.330651Z","shell.execute_reply":"2022-08-23T16:15:38.329595Z","shell.execute_reply.started":"2022-08-23T16:15:38.319208Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'info': {'description': 'SIIM Covid-19 GroupKfold',\n","  'url': None,\n","  'version': 1,\n","  'year': 2022,\n","  'contributor': None,\n","  'date_created': '2022-08-23 16:15:38.322615'},\n"," 'licenses': [{'url': None, 'id': 0, 'name': None}],\n"," 'images': [],\n"," 'type': 'instances',\n"," 'annotations': [],\n"," 'categories': [{'id': 0, 'name': 'Covid_Opacity'}]}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["now = datetime.datetime.now()\n","data = dict(\n","    info=dict(\n","        description='SIIM Covid-19 GroupKfold',\n","        url=None,\n","        version=1,\n","        year=now.year,\n","        contributor=None,\n","        date_created=now.strftime('%Y-%m-%d %H:%M:%S.%f')\n","        ),\n","    licenses=[dict(\n","        url=None,\n","        id=0,\n","        name=None)],\n","    images = [],\n","    type='instances',\n","    annotations=[],\n","    categories=[dict(\n","        id=0,\n","        name='Covid_Opacity')],\n",")\n","data"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T16:15:38.663582Z","iopub.status.busy":"2022-08-23T16:15:38.662817Z","iopub.status.idle":"2022-08-23T16:16:15.671130Z","shell.execute_reply":"2022-08-23T16:16:15.670216Z","shell.execute_reply.started":"2022-08-23T16:15:38.663524Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train images: 3435 \n"," Validation images: 859\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"531b16a504c74b369a872879d27890e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3435 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acb1fbbf6b7745d8827cd1afd74684c7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/859 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train images: 3435 \n"," Validation images: 859\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac2f4e2ec52541c29ff8ea55b99a64e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3435 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6205b46c9b2647e482d2416a4cf09116","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/859 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train images: 3435 \n"," Validation images: 859\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22d881ef609f451dbe4545ea09bc3365","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3435 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b67ecefa717f4e59ba209d930d887ae0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/859 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train images: 3435 \n"," Validation images: 859\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59866648a964430fb5ae79545ebdb89b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3435 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bf78727433f4f3e8b644dea017e2cce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/859 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train images: 3436 \n"," Validation images: 858\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52ec67741f504de2be3c39175c254c60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3436 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf3a5a5253f744fa8b0ac8e3a0b97c2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/858 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["SIZE = 512\n","K_FOLDS = 5\n","\n","for fold in range(K_FOLDS):\n","    train_ids = df_kfold[df_kfold['fold'] != fold].id.unique()\n","    val_ids = df_kfold[df_kfold['fold'] == fold].id.unique()\n","    print(f'Train images: {len(train_ids)} \\n Validation images: {len(val_ids)}')\n","    df_annotations = pd.read_csv(f'/kaggle/input/siim-covid-19-256-512-768-1024-1280/df_train_processed_meta_{SIZE}x{SIZE}.csv')\n","    out_train_json = f'coco_train_{SIZE}x{SIZE}_fold_{fold}.json'\n","    out_val_json = f'coco_val_{SIZE}x{SIZE}_fold_{fold}.json'\n","    data_train = data.copy()\n","    data_train['images'] = []\n","    data_train['annotations'] = []\n","    data_val = data.copy()\n","    data_val['images'] = []\n","    data_val['annotations'] = []\n","    \n","    # Train annotations file loop\n","    for i,img_id in enumerate(tqdm(train_ids)):\n","        data_train['images'].append(\n","            dict(\n","                license=0,\n","                url=None,\n","                file_name=img_id+'.png',\n","                height=SIZE,\n","                width=SIZE,\n","                date_captured=None,\n","                id=i\n","            )\n","        )\n","        img_annotations = df_annotations[df_annotations['id']==img_id]\n","        if len(img_annotations) > 0:\n","            boxes = img_annotations[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n","            box_labels = np.zeros(img_annotations.shape[0])\n","            for box,label in zip(boxes,box_labels):\n","                x1,y1,x2,y2 = (box[0],box[1],box[2],box[3])\n","                area = round((x2-x1)*(y2-y1),1)\n","                bbox=[\n","                    int(x1),\n","                    int(y1),\n","                    int(x2-x1),\n","                    int(y2-y1)\n","                ]\n","                data_train['annotations'].append(\n","                    dict(\n","                    id=len(data_train['annotations']),\n","                    image_id=i,\n","                    category_id=int(label),\n","                    area=int(area),\n","                    bbox=bbox,\n","                    segmentation=[],\n","                    iscrowd=0)\n","                )\n","    with open(os.path.join('/kaggle/working',out_train_json),'w') as fp:\n","                json.dump(data_train,fp,indent=4)\n","            \n","    # Validation annotations loop\n","    \n","    for i,img_id in enumerate(tqdm(val_ids)):\n","        data_val['images'].append(\n","            dict(\n","                license=0,\n","                url=None,\n","                file_name=img_id+'.png',\n","                height=SIZE,\n","                width=SIZE,\n","                date_captured=None,\n","                id=i\n","            )\n","        )\n","        img_annotations = df_annotations[df_annotations['id']==img_id]\n","        if len(img_annotations) > 0:\n","            boxes = img_annotations[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n","            box_labels = np.zeros(img_annotations.shape[0])\n","            for box,label in zip(boxes,box_labels):\n","                x1,y1,x2,y2 = (box[0],box[1],box[2],box[3])\n","                area = round((x2-x1)*(y2-y1),1)\n","                bbox=[\n","                    int(x1),\n","                    int(y1),\n","                    int(x2-x1),\n","                    int(y2-y1)\n","                ]\n","                data_val['annotations'].append(\n","                    dict(\n","                    id=len(data_val['annotations']),\n","                    image_id=i,\n","                    category_id=int(label),\n","                    area=int(area),\n","                    bbox=bbox,\n","                    segmentation=[],\n","                    iscrowd=0)\n","                )\n","    with open(os.path.join('/kaggle/working',out_val_json),'w') as fp:\n","                json.dump(data_val,fp,indent=4)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T16:16:15.673111Z","iopub.status.busy":"2022-08-23T16:16:15.672805Z","iopub.status.idle":"2022-08-23T16:16:16.289096Z","shell.execute_reply":"2022-08-23T16:16:16.288283Z","shell.execute_reply.started":"2022-08-23T16:16:15.673082Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<wandb.sdk.wandb_artifacts.Artifact at 0x7ff56d2fb410>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["artifact = wandb.Artifact('5_fold_train_val_coco_files', type='dataset')\n","for fold in range(K_FOLDS):\n","    artifact.add_file(os.path.join('/kaggle/working',f'coco_train_{SIZE}x{SIZE}_fold_{fold}.json'))\n","    artifact.add_file(os.path.join('/kaggle/working',f'coco_val_{SIZE}x{SIZE}_fold_{fold}.json'))\n","run.log_artifact(artifact)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T16:16:16.290703Z","iopub.status.busy":"2022-08-23T16:16:16.290353Z","iopub.status.idle":"2022-08-23T16:16:26.395815Z","shell.execute_reply":"2022-08-23T16:16:26.394817Z","shell.execute_reply.started":"2022-08-23T16:16:16.290671Z"},"trusted":true},"outputs":[{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='16.279 MB of 16.279 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">GroupKFold_train_test_coco_file_generation</strong>: <a href=\"https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/2zd6bkhl\" target=\"_blank\">https://wandb.ai/alvaromoureupm/Final-Covid19-Detection/runs/2zd6bkhl</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220823_160534-2zd6bkhl/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
